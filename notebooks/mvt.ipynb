{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marginal Value Theorem\n",
    "A place to test experimental parameters for foraging behavior in line with the marginal value theorem.\n",
    "\n",
    "**NOTE: ipywidgets has poor compability with jupyterlab, particularly with versions >= 3.0. If interactive plots below do not display, try running this in a classic jupyter notebook instead.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical tools\n",
    "import numpy as np\n",
    "from scipy.optimize import broyden1\n",
    "\n",
    "# Plotting tools\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "#%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# General tools\n",
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', 'DeprecationWarning')\n",
    "\n",
    "# Custom modules\n",
    "import sys\n",
    "sys.path.insert(0, '../python')\n",
    "import helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectionSlider(widgets.SelectionSlider):\n",
    "    \n",
    "    def __init__(self, *args, return_index=True, transform=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.return_index = return_index\n",
    "        if transform is not None:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = lambda x: x\n",
    "        \n",
    "    def get_interact_value(self):\n",
    "        if self.return_index:\n",
    "            return (self.transform(self.value), self.index)\n",
    "        else:\n",
    "            return self.transform(self.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_kwargs = dict(\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    return_index=True,\n",
    "    transform=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "### Optimal residence time\n",
    "Let's define a patchy environment as consisting of the following parameters:\n",
    "\n",
    "$\\quad T_{p}^{(i)}$: time spent harvesting reward in patch $i$  \n",
    "$\\quad T_{t}^{(i)}$: time spent traveling to patch $i$  \n",
    "$\\quad R^{(i)}(t^{(i)})$: amount of reward harvested in patch $i$ after time $t^{(i)}$ (i.e. the *gain function*)  \n",
    "$\\quad s$: search cost per unit time\n",
    "\n",
    "The average reward intake $\\bar{E}$ across the environment is:\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "\\quad \\bar{E} \n",
    "&= \\frac{\\text{total energy}}{\\text{total time}} \\\\\n",
    "&= \\frac{\\sum_{i} \\left ( R^{(i)}(T_{p}^{(i)}) - sT_{t}^{(i)} \\right )}{\\sum_{i} \\left ( T_{t}^{(i)} + T_{p}^{(i)} \\right )} \\\\\n",
    "&= \\frac{R^{(i)}(T_{p}^{(i)}) - sT_{t}^{(i)} + k^{(i)}}{T_{t}^{(i)} + T_{p}^{(i)} + c^{(i)}}\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "where $k^{(i)} = \\sum_{j \\neq i} \\left ( R^{(j)}(T_{p}^{(j)}) - sT_{t}^{(j)} \\right )$ and $c^{(i)} = \\sum_{j \\neq i} \\left ( T_{t}^{(j)} + T_{p}^{(j)} \\right )$. Given that $\\mathbf{T}_p = \\{T_{p}^{(i)}\\}$ are the only behavioral parameters in this model, we can define an optimal behavior vector as $\\mathbf{T}_p^* = \\{T_{p}^{*(i)}\\}$. To solve for optimal behavior, we differentiate $\\bar{E}$ with respect to $\\mathbf{T}_p$:\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "\\quad \\dfrac{\\partial \\bar{E}}{\\partial \\mathbf{T}_p} \n",
    "&= \\left \\{ \\begin{matrix} ... & \\dfrac{\\partial \\bar{E}}{\\partial \\mathbf{T}_p^{(i)}} & ... \\end{matrix} \\right \\} \\\\\n",
    "&= \\left \\{ \\begin{matrix} ... & \\dfrac{\\partial}{\\partial \\mathbf{T}_p^{(i)}} \\left ( \\dfrac{R^{(i)}(T_{p}^{(i)}) - sT_{t}^{(i)} + k^{(i)}}{T_{t}^{(i)} + T_{p}^{(i)} + c^{(i)}} \\right ) & ... \\end{matrix} \\right \\} \\\\\n",
    "&= \\left \\{ \\begin{matrix} ... & \\dfrac{r^{(i)}(T_{p}^{(i)}) \\left ( T_{t}^{(i)} + T_{p}^{(i)} + c^{(i)} \\right ) - \\left ( R^{(i)}(T_{p}^{(i)}) - sT_{t}^{(i)} + k^{(i)} \\right )}{\\left ( T_{t}^{(i)} + T_{p}^{(i)} + c^{(i)} \\right )^2} & ... \\end{matrix} \\right \\}\n",
    "\\end{align}$\n",
    "\n",
    "\n",
    "and note that $\\bar{E}$ is maximized when $\\frac{\\partial \\bar{E}}{\\partial \\mathbf{T}_p} = \\mathbf{0}$:\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "\\quad \\mathbf{0} &= \\left \\{ \\begin{matrix} ... & \\dfrac{r^{(i)}(T_{p}^{*(i)}) \\left ( T_{t}^{(i)} + T_{p}^{*(i)} + c^{(i)} \\right ) - \\left ( R^{(i)}(T_{p}^{*(i)}) - sT_{t}^{(i)} + k^{(i)} \\right )}{\\left ( T_{t}^{(i)} + T_{p}^{*(i)} + c^{(i)} \\right )^2} & ... \\end{matrix} \\right \\} \\\\\n",
    "&= \\left \\{ \\begin{matrix} ... & r^{(i)}(T_{p}^{*(i)}) \\left ( T_{t}^{(i)} + T_{p}^{*(i)} + c^{(i)} \\right ) - \\left ( R^{(i)}(T_{p}^{*(i)}) - sT_{t}^{(i)} + k^{(i)} \\right ) & ... \\end{matrix} \\right \\} \\\\\n",
    "\\end{align} \\\\\n",
    "\\quad \\Rightarrow r^{(i)}(T_{p}^{*(i)}) \\left ( T_{t}^{(i)} + T_{p}^{*(i)} + c^{(i)} \\right ) = R^{(i)}(T_{p}^{*(i)}) - sT_{t}^{(i)} + k^{(i)} \\\\\n",
    "\\quad \\Rightarrow r^{(i)}(T_{p}^{*(i)}) = \\dfrac{R^{(i)}(T_{p}^{*(i)}) - sT_{t}^{(i)} + k^{(i)}}{T_{t}^{(i)} + T_{p}^{*(i)} + c^{(i)}} = \\bar{E}\n",
    "$\n",
    "\n",
    "or in the single-patch case ($i=1$):\n",
    "\n",
    "$\n",
    "\\quad r(T_{p}^{*}) = \\dfrac{R(T_{p}^{*}) - sT_{t}}{T_{t} + T_{p}^{*}} = \\bar{E}\n",
    "$\n",
    "\n",
    "where $r(t) = \\frac{\\mathrm{d} R}{\\mathrm{d} t}$.\n",
    "\n",
    "Therefore, the optimal patch residence time for each patch $T_{p}^{*(i)}$ occurs when the marginal gain in that patch equals the average rate of return across the environment; this is called the **marginal value theorem** (MVT). If we model the gain function based on an exponentially decaying rate of return within a given patch:\n",
    "\n",
    "$\n",
    "\\quad r(T_{p}) = r_0 e^{-\\frac{T_p}{\\tau}} \\\\\n",
    "\\quad R(T_{p}) = \\int_{0}^{T_p} r(t)dt = r_0 \\tau \\left ( 1 - e^{-\\frac{T_p}{\\tau}} \\right ) + R_0\n",
    "$\n",
    "\n",
    "then, for the single-patch case, the MVT equation becomes:\n",
    "\n",
    "$\n",
    "\\quad r(T_{p}^{*}) = \\dfrac{R(T_{p}^{*}) - sT_{t}}{T_{t} + T_{p}^{*}} \\\\\n",
    "\\quad r_0 e^{-\\frac{T_p^{*}}{\\tau}} = \\dfrac{r_0 \\tau \\left ( 1 - e^{-\\frac{T_p^{*}}{\\tau}} \\right ) + R_0 - sT_{t}}{T_{t} + T_{p}^{*}} \\\\\n",
    "\\quad \\Rightarrow r_0 e^{-\\frac{T_p^{*}}{\\tau}} \\left ( T_{t} + T_{p}^{*} \\right ) = r_0 \\tau - r_0 \\tau  e^{-\\frac{T_p^{*}}{\\tau}} + R_0 - sT_{t} \\\\\n",
    "\\quad \\Rightarrow r_0 e^{-\\frac{T_p^{*}}{\\tau}} \\left ( T_{t} + T_{p}^{*} + \\tau \\right ) - r_0 \\tau - R_0 + sT_{t} = 0\n",
    "$\n",
    "\n",
    "As a sanity check, let's solve for the optimal residence time a slightly different way. If we are trying to maximize our average harvest rate across an environment, $\\bar{R}(T_p)$, then we can simply set the derivative of this intake rate to zero and solve to find the maximum. First, the derivative is:\n",
    "\n",
    "$\n",
    "\\quad \\bar{R}(T_p) = \\dfrac{R(T_{p}) - sT_{t}}{T_{t} + T_{p}} \\\\\n",
    "\\begin{align}\n",
    "\\quad \\dfrac{d \\bar{R}}{d T_p} \n",
    "&= \\dfrac{\\dfrac{d}{d T_p} \\left ( R(T_p) - sT_t \\right ) \\left ( T_t + T_p \\right ) - \\left ( R(T_p) - sT_t \\right ) \\left ( \\dfrac{d}{d T_p} \\left ( T_t + T_p \\right ) \\right )}{\\left ( T_t + T_p \\right )^2} \\quad \\text{(by the product rule)} \\\\\n",
    "&= \\dfrac{\\left ( \\dfrac{d R}{d T_p} \\right ) \\left ( T_t + T_p \\right ) - R(T_p) + sT_t}{\\left ( T_t + T_p \\right )^2} \\\\\n",
    "&= \\dfrac{r(T_p) \\left ( T_t + T_p \\right ) - R(T_p) + sT_t}{\\left ( T_t + T_p \\right )^2} \\quad \\text{(by definition)}\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "Setting this to zero, we get:\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "\\quad 0 \n",
    "&= \\dfrac{r(T^*_p) \\left ( T_t + T^*_p \\right ) - R(T^*_p) + sT_t}{\\left ( T_t + T^*_p \\right )^2} \\\\\n",
    "&= r(T^*_p) \\left ( T_t + T^*_p \\right ) - R(T^*_p) + sT_t \\\\\n",
    "&\\Rightarrow r(T^*_p) = \\dfrac{R(T^*_p) - sT_t}{T_t + T^*_p}\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "arriving at the same equation as above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "### Additional rewards and costs\n",
    "Additional travel time can be modeled as beneficial rest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter tool\n",
    "Let's rewrite the code to 1) better display the data and 2) be a single code block to visualize any parameter manipulation.\n",
    "\n",
    "There are five parameters ($T_P, T_T, R_0, r_0, \\tau$), of which we can display three at a time using heatmaps. Because one of those, the unknown, is fixed, we have $C^4_2 = \\frac{4!}{2! 2!} = 6$ graphs to display. Instead of displaying all graphs at once, we will instead allow the user to select which variable(s) to plot using either 1D (curve) or 2D (heatmap) visualization. Additionally, we will implement a selection tool for each fixed variable (i.e. not displayed) in order to quickly update the plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Behavior parameters\n",
    "#t_p = np.linspace(5.0, 60.0, num=56)\n",
    "t_p = None\n",
    "t_t = np.linspace(1.0, 30.0, num=30)\n",
    "\n",
    "# Environment parameters\n",
    "# Remember, R_0 / r_0 must be ≥ t_t, otherwise R_0 will default to zero!\n",
    "R_0 = np.array([0.0])\n",
    "r_0 = np.linspace(0.5, 5.0, num=19)\n",
    "tau = np.linspace(1.0, 40.0, num=40)\n",
    "\n",
    "# Parameters (do not change order!!!)\n",
    "params = {'t_p': t_p,\n",
    "          't_t': t_t,\n",
    "          'R_0': R_0,\n",
    "          'r_0': r_0,\n",
    "          'tau': tau}\n",
    "assert len([k for k, v in params.items() if v is None]) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = {k: v for k, v in params.items() if v is not None}\n",
    "name = [k for k, v in params.items() if v is None][0]\n",
    "soln, R_opt, is_solvable = helper.get_optimal_values(**params, \n",
    "                                                     return_solvable=True, \n",
    "                                                     min_value=0.01, \n",
    "                                                     max_value=1000.0)\n",
    "Y = {name: soln,\n",
    "     'R_opt': R_opt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib widget # calling the magic function again closes previous figures\n",
    "\n",
    "# Parameter settings\n",
    "x_name = 'tau'\n",
    "\n",
    "# Create widgets\n",
    "w1D = {}\n",
    "for name, x in X.items():\n",
    "    if name != x_name:\n",
    "        w1D[name] = SelectionSlider(options=x,\n",
    "                                    value=x[0],\n",
    "                                    description=name,\n",
    "                                    **default_kwargs)\n",
    "\n",
    "# Create initial plot\n",
    "fig1D, ax1D = plt.subplots(1, 2, figsize=(8.0, 3.0))\n",
    "idx = tuple([0 if name != x_name else slice(None) for name, x in X.items()])\n",
    "lines = []\n",
    "for i, (name, y) in enumerate(Y.items()):\n",
    "    h, = ax1D[i].plot(X[x_name], y[idx], color='black', alpha=0.7)\n",
    "    lines.append(h)\n",
    "    ax1D[i].set_xlabel(x_name)\n",
    "    ax1D[i].set_ylabel(name)\n",
    "    ax1D[i].set_title('{} vs. {}'.format(name, x_name))\n",
    "plt.tight_layout()\n",
    "        \n",
    "# Create update function\n",
    "x_idx = list(X.keys()).index(x_name)\n",
    "def update_plot(**kwargs):\n",
    "    # Get indices to display\n",
    "    idx = [val[1] for name, val in kwargs.items()] # val = (w.value, w.index)\n",
    "    idx.insert(x_idx, slice(None)) # slice across x1 axis\n",
    "    idx = tuple(idx)\n",
    "    \n",
    "    # Update curve\n",
    "    for i, (name, y) in enumerate(Y.items()):\n",
    "        lines[i].set_ydata(y[idx])\n",
    "        ax1D[i].relim()\n",
    "        ax1D[i].autoscale_view()\n",
    "    fig1D.canvas.draw_idle()\n",
    "    \n",
    "widgets.interact(update_plot, **w1D);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib widget # calling the magic function again closes previous figures\n",
    "\n",
    "# Parameter settings\n",
    "x1_name = 't_t'\n",
    "x2_name = 'tau'\n",
    "Y_range = [0.0, 1000.0]\n",
    "\n",
    "# Create widgets\n",
    "w2D = {} # different name from above because widgets persist in background\n",
    "for name, x in X.items():\n",
    "    if name not in [x1_name, x2_name]:\n",
    "        w2D[name] = SelectionSlider(options=x,\n",
    "                                    value=x[0],\n",
    "                                    description=name,\n",
    "                                    **default_kwargs)\n",
    "\n",
    "# Create color palette\n",
    "palette = copy.copy(plt.cm.coolwarm)\n",
    "palette.set_under('black', Y_range[0])\n",
    "palette.set_over('black', Y_range[1])\n",
    "palette.set_bad(alpha=0.0)\n",
    "        \n",
    "# Determine axis labels \n",
    "# NOTE: in imshow(), first index is # rows, second index is # cols\n",
    "x1_idx = list(X.keys()).index(x1_name)\n",
    "x2_idx = list(X.keys()).index(x2_name)\n",
    "if x1_idx < x2_idx:\n",
    "    x1_label = x2_name\n",
    "    x2_label = x1_name\n",
    "else:\n",
    "    x1_label = x1_name\n",
    "    x2_label = x2_name\n",
    "    \n",
    "# Create initial heatmaps\n",
    "fig2D, ax2D = plt.subplots(1, 2, figsize=(8.0, 3.0))\n",
    "idx = tuple([0 if name not in [x1_name, x2_name] else slice(None) \n",
    "             for name, x in X.items()])\n",
    "images = []\n",
    "cbars = []\n",
    "for i, (name, y) in enumerate(Y.items()):\n",
    "    # Create heatmap\n",
    "    extent = [X[x1_label][0], X[x1_label][-1], X[x2_label][0], X[x2_label][-1]]\n",
    "    im = ax2D[i].imshow(y[idx],\n",
    "                        cmap=palette,\n",
    "                        aspect='auto',\n",
    "                        origin='lower',\n",
    "                        vmin=y[idx].min(),\n",
    "                        vmax=y[idx].max(),\n",
    "                        extent=extent)\n",
    "    images.append(im)\n",
    "    ax2D[i].set_xlabel(x1_label)\n",
    "    ax2D[i].set_ylabel(x2_label)\n",
    "    ax2D[i].set_title('{} vs. ({}, {})'.format(name, x1_name, x2_name))\n",
    "    \n",
    "    # Create colorbar\n",
    "    cbar = fig2D.colorbar(im, ax=ax2D[i])\n",
    "    cbar.set_label(name)\n",
    "    cbars.append(cbar)\n",
    "    \n",
    "plt.tight_layout()\n",
    "\n",
    "# Create update function\n",
    "def update_heatmap(**kwargs):\n",
    "    # Get indices to display\n",
    "    idx = [val[1] for name, val in kwargs.items()] # val = (w.value, w.index)\n",
    "    idx.insert(x1_idx, slice(None)) # slice across x1 axis\n",
    "    idx.insert(x2_idx, slice(None)) # slice across x2 axis\n",
    "    idx = tuple(idx)\n",
    "    \n",
    "    # Update heatmaps\n",
    "    for i, (name, y) in enumerate(Y.items()):\n",
    "        images[i].set_data(y[idx])\n",
    "        cbars[i].mappable.set_clim(vmin=y[idx].min(), vmax=y[idx].max())\n",
    "        ax2D[i].relim()\n",
    "        ax2D[i].autoscale_view()\n",
    "    fig2D.canvas.draw_idle()\n",
    "    \n",
    "widgets.interact(update_heatmap, **w2D);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter selection\n",
    "Using the tool above, we want to select parameter sets that will maximize our behavioral readout (namely, residence time) given constraints of the animal, rig, etc. Thus, our goal is the following:\n",
    "\n",
    "Find:\n",
    "\n",
    "$\\quad \\{T_P^*, T_T, R_0, r_0, \\tau\\} \\quad s.t. \\quad \\{T_T\\} = argmax \\left ( \\dfrac{\\partial T_P^*}{\\partial T_T} \\right ) \\, , \\, \\{\\tau\\} = argmax \\left ( \\dfrac{\\partial T_P^*}{\\partial \\tau} \\right )$\n",
    "\n",
    "given:\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "\\quad &5 \\leq T_P^* \\leq 40 \\, seconds \\quad &(1) \\\\\n",
    "\\quad &N_P^* \\geq 20 \\, in \\, 30 \\, mins \\quad &(2) \\\\\n",
    "\\quad &R_t^* N_P^* \\leq 600 \\, uL \\quad &(3) \\\\\n",
    "\\quad &\\dfrac{R_t^*}{V_R} \\geq 3 \\quad &(4)\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "Let's quickly give justification for our constraints. The lower bound of (1) arises from needing a reasonable residence time to a) perform the task and b) accrue multiple rewards to allow for stochasticity to (eventually) play a role. The upper bound of (1) is an objective estimate of the maximum duration for which mice are comfortable poking, after which they unpoke due to an exploration drive, discomfort, etc. These numbers came from the residence times in the preliminary data: the lower bound from $\\mu_{T_P} - \\sigma_{T_P}$ and the upper bound from $\\mu_{T_P} + \\sigma_{T_P}$ in environments with the smallest and largest $T_P^*$, respectively. The constraint (2) comes from the observation in preliminary data that roughly 20 patches in 30 minutes is a good cutoff for distinguishing \"good\" from \"bad\" sessions. The constraint on total reward harvested in (3) assumes that after 20 patches of 5-6 five uL rewards, mice become less motivated (less hungry) to continue to engage in the foraging task. Lastly, the constraint (4) dictates that the number of harvested rewards at optimal leaving time must be at least 3, with the idea being that anything less a) is too easy to develop simple heuristics to solve, b) diminishes stochasticity introduced later on (i.e. there can only be so much variability of reward times for few rewards), and/or c) reduces the rate at which the animal is gaining information about the patch dynamics. From (3) and (4), it immediately follows that:\n",
    "\n",
    "$\n",
    "\\quad 3 V_R \\leq R_t^* \\leq \\dfrac{600 \\, uL}{N_P^*} \\quad (5)\n",
    "$\n",
    "\n",
    "Focusing on the maximization problem, we see that we want to find a set $\\{T_T, \\tau\\}$ that maximizes the derivatives of the optimal residence time with respect to each parameter. Looking at our parameter tool, we can see that for both parameters, the derivative is maximized at the smallest possible value; in other words, the second derivatives appear to be monotonically decreasing. This suggests that we should simply operate on the extrema within our allowed parameter space given our constraints; that is, choose the smallest and largest values of $T_T$ and $\\tau$ that still operate within our constrained space. \n",
    "\n",
    "There's a couple of approaches to tackle this problem, each with its own underlying assumptions:\n",
    "1. Jointly optimize $\\{T_T, \\tau\\}$ by maximizing $\\left \\| \\nabla T_P^* \\right \\| = \\left \\| \\left \\langle \\dfrac{\\partial T_P^*}{\\partial T_T}, \\dfrac{\\partial T_P^*}{\\partial \\tau} \\right \\rangle \\right \\| = \\sqrt{\\left ( \\dfrac{\\partial T_P^*}{\\partial T_T} \\right )^2 + \\left ( \\dfrac{\\partial T_P^*}{\\partial \\tau} \\right )^2}$. Choose the starting point to be the smallest allowed travel time and decay rate values (which maximizes the partial derivatives), and then follow a path based on gradient ascent until the maximum possible travel time is reached.\n",
    "2. Fix $T_T$ to the average travel time for an animal on a fixed track length. Choose $\\tau$ that maximize the change in $T_P^*$ holding either $T_T$ fixed (decay rate manipulation) or $\\tau$ fixed (travel time manipulation).\n",
    "\n",
    "In the first approach, we model the foraging environment as a more continuous space in which the perceived travel time and decay rate may move more fluidly despite fixed track lengths and true decay rates. In this case, it may be best to stay on a path in which the gradient is maximized so that for any change in the perceived parameters, the change in optimal residence time (our primary behavioral readout!) is maximized. The higher degree of stochasticity in the reward times, the more this approach becomes favorable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second approach, we assume a more deterministic environment in which travel time is highly correlated with track length and (perceived) decay rate is relatively stable and easy to learn. In this case, we can assume that $T_T$ is already predetermined by the combination of track length and animal behavior (speed, engagement, etc.), so we can simply find the average travel time for the one and four meter tracks. (Note that the choice of extrema was already in our track design anyways: we made the smallest and largest tracks possible.) Moreover, $R_0$ is zero by design, so we can ignore that parameter for our calculations. That leaves us with just $\\tau$ and $r_0$.\n",
    "\n",
    "Working in our favor is the independence of $r_0$ from $T_P^*$. The initial reward rate affects the reward harvested for a given task but does not influence the optimal leaving time for the task, regardless of the point in parameter space. Thus we can treat our selection of $\\tau$ and $r_0$ independently: $\\tau$ will influence our first two constraints, $r_0$ our last constraint (we will choose $\\tau$ first so that $N_P^*$ becomes a known quantity.). \n",
    "\n",
    "First, let's focus on $\\tau$. For the one-meter linear track, the travel times were approximately 4-5 seconds, whereas preliminary data for the three-meter S-track were 11-12 seconds. We'll assume that the four-meter L-track will have travel times of 15 seconds. In the first case, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current thoughts:\n",
    "- Finsh out gradient approach by plotting, side-by-side: dTp/dTt, dTp/dtau, ||del T_p||, direction of del T_p (arrow diagram?)\n",
    "- Looking at the initial gradient diagrams, there's really no middle ground for maximizing ||del T_p||; you either choose mostly maximizing dT_p/dTt (which occurs at low Tt, high tau) or mostly maximizing dT_p/dtau (which occurs at high Tt, low tau).\n",
    "- Maybe this leads us to choose two tau values, one that maximizes dT_p/dTt (which will be a high tau value) and one that maximizes dT_p/dtau (which will be a low tau value). These tau will be constrained by the limitations above, so essentially we'll be choosing the lowest and highest possible allowed values of tau (number of rewards, perceptable decay, etc.). Then, when combined with the travel times that are fixed by the track lengths, we have four possible combinations. From these four data points, we will lastly choose our r_0 value based on the reward constraints.\n",
    "- From the behavior data analysis, it appears that:\n",
    "    1. Travel time should be between 5.5 and 43 seconds.\n",
    "    2. The maximum accrued reward over a session should be 400 uL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache current slice of solutions for given (r0, R0)\n",
    "# Because T_P is independent of both r0 and R0, any slice\n",
    "# will give the same values and is valid for our analysis below.\n",
    "assert t_p is None # analysis assumes we solved for T_P\n",
    "idx = tuple([0 if name not in [x1_name, x2_name] else slice(None) \n",
    "             for name, x in X.items()])\n",
    "y = Y['t_p'][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, plot ratio of T_P to tau to assess permissible values\n",
    "fig, ax = plt.subplots()\n",
    "cmap = plt.get_cmap('coolwarm')\n",
    "thresh = [1.0, -np.log(0.5)]\n",
    "\n",
    "# Plot boundaries\n",
    "x1 = X[x1_label] # tau\n",
    "x2 = X[x2_label] # t_t\n",
    "for thresh_ in thresh:\n",
    "    # Estimate boundary in (x1, x2) space where ratio crosses threshold\n",
    "    idx = np.argwhere(np.logical_and(y[:-1, :] / x1[np.newaxis, :] <= thresh_,\n",
    "                                     y[1:, :] / x1[np.newaxis, :] > thresh_))\n",
    "    A = np.vstack([x1[idx[:, 1]], np.ones(idx.shape[0])]).T\n",
    "    (m, b) = np.linalg.lstsq(A, x2[idx[:, 0]], rcond=None)[0]\n",
    "\n",
    "    # Plot estimated boundary\n",
    "    ax.plot(x1[idx[:,1]],\n",
    "            m*x1[idx[:,1]] + b,\n",
    "            color='black',\n",
    "            linestyle='--',\n",
    "            label=r'$\\dfrac{T_P}{\\tau}$' + ' = {:.2f}'.format(thresh_))\n",
    "\n",
    "# Plot heatmap of ratio values\n",
    "img = ax.imshow(y/x1[np.newaxis, :], \n",
    "                cmap=cmap, \n",
    "                vmin=0.0,\n",
    "                vmax=2.0,  \n",
    "                origin='lower', \n",
    "                extent=extent)\n",
    "cb = fig.colorbar(img, ax=ax, ticks=[0.0, 0.5, 1.0, 1.5, 2.0])\n",
    "\n",
    "# Label plot\n",
    "ax.set_title('estimated boundary for leaving time')\n",
    "ax.set_xlabel(x1_label)\n",
    "ax.set_ylabel(x2_label)\n",
    "cb.ax.set_yticklabels(['0.0', '0.5', '1.0', '1.5', '2.00+'])\n",
    "cb.ax.set_ylabel(r'$\\dfrac{T_P}{\\tau}$')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot gradient wrt travel time and decay rate\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 8))\n",
    "cmap = plt.get_cmap('BrBG') # different color scheme to avoid confusion\n",
    "\n",
    "# Estimate partial derivatives and gradient\n",
    "dydtt = np.diff(y, axis=0)\n",
    "dydtau = np.diff(y, axis=1)\n",
    "grad = np.sqrt(dydtt[:, 1:]**2 + dydtau[1:, :]**2)\n",
    "\n",
    "# Plot partial derivatives\n",
    "img = ax[0, 0].imshow(dydtt, \n",
    "                      cmap=cmap,\n",
    "                      origin='lower',  \n",
    "                      #vmin=grad.min(),\n",
    "                      #vmax=grad.max(),\n",
    "                      extent=extent)\n",
    "fig.colorbar(img, ax=ax[0, 0], shrink=0.6)\n",
    "ax[0, 0].set_title(r'$\\dfrac{\\partial T_P}{\\partial T_T}$')\n",
    "img = ax[0, 1].imshow(dydtau, \n",
    "                      cmap=cmap,\n",
    "                      origin='lower',\n",
    "                      #vmin=grad.min(),\n",
    "                      #vmax=grad.max(),\n",
    "                      extent=extent)\n",
    "cbar = fig.colorbar(img, ax=ax[0, 1], shrink=0.6)\n",
    "ax[0, 1].set_title(r'$\\dfrac{\\partial T_P}{\\partial \\tau}$')\n",
    "\n",
    "# Plot gradient magnitude\n",
    "img = ax[1, 0].imshow(grad,\n",
    "                      cmap=cmap,\n",
    "                      origin='lower',\n",
    "                      vmin=grad.min(),\n",
    "                      vmax=grad.max(),\n",
    "                      extent=extent)\n",
    "cbar = fig.colorbar(img, ax=ax[1, 0], shrink=0.6)\n",
    "ax[1, 0].set_title(r'$\\left \\|\\| \\nabla T_P^* \\right \\|\\|$')\n",
    "\n",
    "# Plot gradient direction overlaid on contour map\n",
    "ax[1, 1].contour(y, \n",
    "                 cmap=palette, \n",
    "                 origin='lower', \n",
    "                 extent=extent)\n",
    "ax[1, 1].quiver(X['tau'][1:], X['t_t'][1:], \n",
    "                dydtau[1:, :],dydtt[:, 1:], grad, \n",
    "                cmap=cmap, \n",
    "                angles='xy')\n",
    "ax[1, 1].set_title('contour and quiver plot')\n",
    "\n",
    "# Label axes\n",
    "for ax_ in ax.reshape(-1):\n",
    "    ax_.set_xlabel(x1_label)\n",
    "    ax_.set_ylabel(x2_label)\n",
    "\n",
    "plt.tight_layout();\n",
    "\n",
    "(left, bottom, w_old, h_old) = ax[1, 1].get_position().bounds\n",
    "(_, _, w_new, h_new) = ax[1, 0].get_position().bounds\n",
    "ax[1, 1].set_position((left + (w_old - w_new)/2, \n",
    "                       bottom + (h_old - h_new)/2,\n",
    "                       w_new, \n",
    "                       h_new));\n",
    "\n",
    "plt.savefig('/home/james/Desktop/mvt_params.jpg', dpi=300, fmt='jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's digest the above plots. First, looking at the boundary condition where $\\frac{T_P^*}{\\tau} \\geq 1$, we see that the corner of the plot with small $T_T$ and large $\\tau$ may be problematic, since the area in $(T_T, \\tau)$ space defined by $\\frac{T_P^*}{\\tau} < 1$ corresponds to a less perceptible decay rate (the reward rate will still be greater than $\\frac{r_0}{e}$ upon optimal leaving)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, plot minimum and maximum r_0 within constraints for each point (T_T, tau)\n",
    "v_r = 2.0 # volume per reward (uL)\n",
    "n_r_min = 3 # minimum number of discrete rewards per patch at optimal leaving time\n",
    "R_max = 400 # maximum amount of reward (uL) in session\n",
    "\n",
    "r0_min = lambda t_p, tau: (n_r_min*v_r)/(tau*(1 - np.exp(-t_p/tau)))\n",
    "r0_max = lambda t_p, tau, t_t: R_max/((1800/(t_p + t_t))*tau*(1 - np.exp(-t_p/tau)))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "img = ax[0].imshow(r0_min(y, tau[np.newaxis, :]),\n",
    "                      cmap=cmap,\n",
    "                      origin='lower',  \n",
    "                      #vmin=grad.min(),\n",
    "                      #vmax=grad.max(),\n",
    "                      extent=extent)\n",
    "fig.colorbar(img, ax=ax[0], shrink=0.6)\n",
    "\n",
    "img = ax[1].imshow(r0_max(y, tau[np.newaxis, :], t_t[:, np.newaxis]),\n",
    "                      cmap=cmap,\n",
    "                      origin='lower',  \n",
    "                      #vmin=grad.min(),\n",
    "                      #vmax=grad.max(),\n",
    "                      extent=extent)\n",
    "fig.colorbar(img, ax=ax[1], shrink=0.6);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "ax.plot_surface(tau[np.newaxis, :],\n",
    "                t_t[:, np.newaxis],\n",
    "                r0_min(y, tau[np.newaxis, :]),\n",
    "                cmap=cmap,\n",
    "                alpha=0.5,\n",
    "                linewidths=0.7,\n",
    "                edgecolors='gray')\n",
    "\n",
    "Z = r0_max(y, tau[np.newaxis, :], t_t[:, np.newaxis])\n",
    "ax.plot_surface(tau[np.newaxis, :],\n",
    "                t_t[:, np.newaxis],\n",
    "                r0_max(y, tau[np.newaxis, :], t_t[:, np.newaxis]),\n",
    "                cmap=cmap,\n",
    "                alpha=0.5,\n",
    "                linewidths=0.7,\n",
    "                edgecolors='black')\n",
    "cset = ax.contour(tau[np.newaxis, :]*np.ones(Z.shape),\n",
    "                  t_t[:, np.newaxis]*np.ones(Z.shape),\n",
    "                  r0_max(y, tau[np.newaxis, :], t_t[:, np.newaxis]), \n",
    "                  zdir='x', \n",
    "                  offset=-5, \n",
    "                  cmap=cmap)\n",
    "ax.set_xlim([0.0, 40.0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit environment to behavior\n",
    "Given preferred patch residence and travel times, what is the environment in which such behavior is optimal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Behavior parameters (fixed)\n",
    "t_p = 20\n",
    "t_t = 10\n",
    "\n",
    "# Environment parameters (varied)\n",
    "# Remember, R_0 / r_0 must be ≥ t_t, otherwise R_0 will default to zero!\n",
    "R_0 = np.array([0.0, 2.0, 6.0, 8.0, 10.0, 12.0])\n",
    "r_0 = np.arange(50, 501, 25)/100\n",
    "\n",
    "# Solve for tau, optimum cumulative reward\n",
    "tau = np.zeros([R_0.shape[0], r_0.shape[0]])\n",
    "R_opt = np.zeros([R_0.shape[0], r_0.shape[0]])\n",
    "is_solvable = np.ones([R_0.shape[0], r_0.shape[0]], dtype=np.bool)\n",
    "for i, R_0_ in enumerate(R_0):\n",
    "    tau[i, :], R_opt[i, :], is_solvable[i, :] = get_optimal_values(t_p=t_p, \n",
    "                                                                   t_t=t_t, \n",
    "                                                                   R_0=R_0_, \n",
    "                                                                   r_0=r_0, \n",
    "                                                                   return_solvable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(tau.shape[0], 2, figsize=(10, 4*tau.shape[0]))\n",
    "\n",
    "for i in range(tau.shape[0]):\n",
    "    ax[i, 0].plot(r_0[is_solvable[i]], tau[i, is_solvable[i]], linestyle='-', color='gray')\n",
    "    ax[i, 0].plot(r_0[np.invert(is_solvable[i])], tau[i, np.invert(is_solvable[i])], linestyle='--', color='gray') \n",
    "    ax[i, 0].set_xlabel('r_0 (uL/s)')\n",
    "    ax[i, 0].set_ylabel('tau (s)')\n",
    "    ax[i, 0].set_title('t_p=%d, t_t=%d, R_0=%d' % (t_p, t_t, R_0[i]))\n",
    "    ax[i, 0].set_yscale('log')\n",
    "    \n",
    "    ax[i, 1].plot(r_0[is_solvable[i]], R_opt[i, is_solvable[i]], linestyle='-', color='gray')\n",
    "    ax[i, 1].plot(r_0[np.invert(is_solvable[i])], R_opt[i, np.invert(is_solvable[i])], linestyle='--', color='gray')\n",
    "    ax[i, 1].set_xlabel('r_0 (uL/s)')\n",
    "    ax[i, 1].set_ylabel('R_opt (uL)')\n",
    "    ax[i, 1].set_title('t_p=%d, t_t=%d, R_0=%d' % (t_p, t_t, R_0[i]))\n",
    "\n",
    "ax[0, 0].set_ylim([1.0, 100.0])    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit behavior to environment\n",
    "Given environmental parameters, what is optimum behavior?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Behavior parameters\n",
    "t_t = 10\n",
    "\n",
    "# Environment parameters\n",
    "# Remember, R_0 / r_0 must be ≥ t_t, otherwise R_0 will default to zero!\n",
    "R_0 = np.array([0.0])\n",
    "r_0 = np.arange(50, 501, 50)/100\n",
    "tau = np.arange(10, 60, 5)\n",
    "\n",
    "# Solve for residence time, optimum cumulative reward\n",
    "t_p = np.zeros([tau.shape[0], r_0.shape[0]])\n",
    "R_opt = np.zeros([tau.shape[0], r_0.shape[0]])\n",
    "is_solvable = np.ones([tau.shape[0], r_0.shape[0]], dtype=np.bool)\n",
    "for i, tau_ in enumerate(tau):\n",
    "    t_p[i, :], R_opt[i, :], is_solvable[i, :] = get_optimal_values(t_t=t_t, \n",
    "                                                                   R_0=R_0, \n",
    "                                                                   r_0=r_0,\n",
    "                                                                   tau=tau_,\n",
    "                                                                   return_solvable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(t_p.shape[0], 2, figsize=(10, 20))\n",
    "\n",
    "for i in range(t_p.shape[0]):\n",
    "    ax[i, 0].plot(r_0[is_solvable[i]], t_p[i, is_solvable[i]], linestyle='-', color='gray')\n",
    "    ax[i, 0].plot(r_0[np.invert(is_solvable[i])], t_p[i, np.invert(is_solvable[i])], linestyle='--', color='gray') \n",
    "    ax[i, 0].set_xlabel('r_0 (uL/s)')\n",
    "    ax[i, 0].set_ylabel('t_p (s)')\n",
    "    ax[i, 0].set_title('tau=%d, t_t=%d, R_0=%d' % (tau[i], t_t, R_0))\n",
    "    \n",
    "    ax[i, 1].plot(r_0[is_solvable[i]], R_opt[i, is_solvable[i]], linestyle='-', color='gray')\n",
    "    ax[i, 1].plot(r_0[np.invert(is_solvable[i])], R_opt[i, np.invert(is_solvable[i])], linestyle='--', color='gray')\n",
    "    ax[i, 1].set_xlabel('r_0 (uL/s)')\n",
    "    ax[i, 1].set_ylabel('R_opt (uL)')\n",
    "    ax[i, 1].set_title('tau=%d, t_t=%d, R_0=%d' % (tau[i], t_t, R_0))\n",
    "\n",
    "#ax[0, 0].set_ylim([0.0, 100.0])    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vary travel time and solve for residence time; see what values double residence time\n",
    "# Behavior parameters\n",
    "t_t = np.arange(5, 41, 5)\n",
    "\n",
    "# Environment parameters\n",
    "# Remember, R_0 / r_0 must be ≥ t_t, otherwise R_0 will default to zero!\n",
    "R_0 = np.array([0.0])\n",
    "r_0 = np.arange(50, 501, 50)/100\n",
    "tau = np.array([24.0])\n",
    "\n",
    "# Solve for residence time, optimum cumulative reward\n",
    "t_p = np.zeros([t_t.shape[0], r_0.shape[0]])\n",
    "R_opt = np.zeros([t_t.shape[0], r_0.shape[0]])\n",
    "is_solvable = np.ones([t_t.shape[0], r_0.shape[0]], dtype=np.bool)\n",
    "for i, t_t_ in enumerate(t_t):\n",
    "    t_p[i, :], R_opt[i, :], is_solvable[i, :] = get_optimal_values(t_t=t_t_, \n",
    "                                                                   R_0=R_0, \n",
    "                                                                   r_0=r_0,\n",
    "                                                                   tau=tau,\n",
    "                                                                   return_solvable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(t_p.shape[0], 2, figsize=(10, 20))\n",
    "\n",
    "for i in range(t_p.shape[0]):\n",
    "    ax[i, 0].plot(r_0[is_solvable[i]], t_p[i, is_solvable[i]], linestyle='-', color='gray')\n",
    "    ax[i, 0].plot(r_0[np.invert(is_solvable[i])], t_p[i, np.invert(is_solvable[i])], linestyle='--', color='gray') \n",
    "    ax[i, 0].set_xlabel('r_0 (uL/s)')\n",
    "    ax[i, 0].set_ylabel('t_p (s)')\n",
    "    ax[i, 0].set_title('tau=%d, t_t=%d, R_0=%d' % (tau, t_t[i], R_0))\n",
    "    \n",
    "    ax[i, 1].plot(r_0[is_solvable[i]], R_opt[i, is_solvable[i]], linestyle='-', color='gray')\n",
    "    ax[i, 1].plot(r_0[np.invert(is_solvable[i])], R_opt[i, np.invert(is_solvable[i])], linestyle='--', color='gray')\n",
    "    ax[i, 1].set_xlabel('r_0 (uL/s)')\n",
    "    ax[i, 1].set_ylabel('R_opt (uL)')\n",
    "    ax[i, 1].set_title('tau=%d, t_t=%d, R_0=%d' % (tau, t_t[i], R_0))\n",
    "\n",
    "#ax[0, 0].set_ylim([0.0, 100.0])    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How does optimal harvest rate change with different environments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Behavior parameters\n",
    "t_t = 5\n",
    "\n",
    "# Environment parameters\n",
    "# Remember, R_0 / r_0 must be ≥ t_t, otherwise R_0 will default to zero!\n",
    "R_0 = np.array([0.0])\n",
    "r_0 = np.arange(50, 501, 50)/100\n",
    "tau = np.arange(10, 30, 1)\n",
    "\n",
    "# Solve for residence time, optimum cumulative reward\n",
    "t_p = np.zeros([r_0.shape[0], tau.shape[0]])\n",
    "R_opt = np.zeros([r_0.shape[0], tau.shape[0]])\n",
    "is_solvable = np.ones([r_0.shape[0], tau.shape[0]], dtype=np.bool)\n",
    "for i, r_0_ in enumerate(r_0):\n",
    "    t_p[i, :], R_opt[i, :], is_solvable[i, :] = get_optimal_values(t_t=t_t, \n",
    "                                                                   R_0=R_0, \n",
    "                                                                   r_0=r_0_,\n",
    "                                                                   tau=tau,\n",
    "                                                                   return_solvable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(r_0.shape[0], 2, figsize=(10, 20))\n",
    "\n",
    "for i in range(r_0.shape[0]):\n",
    "    ax[i, 0].plot(tau[is_solvable[i]], t_p[i, is_solvable[i]], linestyle='-', color='gray')\n",
    "    ax[i, 0].plot(tau[np.invert(is_solvable[i])], t_p[i, np.invert(is_solvable[i])], linestyle='--', color='gray') \n",
    "    ax[i, 0].set_xlabel('tau (uL/s)')\n",
    "    ax[i, 0].set_ylabel('t_p (s)')\n",
    "    ax[i, 0].set_title('r_0=%.2f, t_t=%d, R_0=%d' % (r_0[i], t_t, R_0))\n",
    "    \n",
    "    ax[i, 1].plot(tau[is_solvable[i]], R_opt[i, is_solvable[i]]/(t_t + t_p[i, is_solvable[i]]), \n",
    "                  linestyle='-', color='gray')\n",
    "    ax[i, 1].plot(tau[np.invert(is_solvable[i])], R_opt[i, np.invert(is_solvable[i])]/(t_t + t_p[i, np.invert(is_solvable[i])]), \n",
    "                  linestyle='--', color='gray') \n",
    "    ax[i, 1].set_xlabel('tau (uL/s)')\n",
    "    ax[i, 1].set_ylabel('hr (uL/s)')\n",
    "    ax[i, 1].set_title('r_0=%.2f, t_t=%d, R_0=%d' % (r_0[i], t_t, R_0))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_t_ = 10\n",
    "R_0_ = R_0[0]\n",
    "r_0_ = 2.0\n",
    "t_p_ = t_p[np.argwhere(t_t == t_t_)[0], np.argwhere(r_0 == r_0_)[0]] \n",
    "tau_ = tau[0]\n",
    "\n",
    "print('t_p = %.2f, t_t = %.2f, R_0 = %.2f, r_0 = %.2f, tau = %.2f' % (t_p_, t_t_, R_0_, r_0_, tau_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_t_ = 25\n",
    "R_0_ = R_0[0]\n",
    "r_0_ = 2.0\n",
    "t_p_ = t_p[np.argwhere(t_t == t_t_)[0], np.argwhere(r_0 == r_0_)[0]] \n",
    "tau_ = tau[0]\n",
    "\n",
    "print('t_p = %.2f, t_t = %.2f, R_0 = %.2f, r_0 = %.2f, tau = %.2f' % (t_p_, t_t_, R_0_, r_0_, tau_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed plotting tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(2, 6, figsize=(15, 5))\n",
    "\n",
    "k = 0\n",
    "Y_range = [0.0, 50.0]\n",
    "\n",
    "# Create custom colormap\n",
    "# (see https://matplotlib.org/3.1.0/gallery/images_contours_and_fields/image_masked.html)\n",
    "palette = copy.copy(plt.cm.coolwarm)\n",
    "palette.set_under('black', Y_range[0])\n",
    "palette.set_over('black', Y_range[1])\n",
    "palette.set_bad(alpha=0.0)\n",
    "for i, (name, x) in enumerate(X.items()):\n",
    "    # Plot parameter vs. unknown\n",
    "    if isinstance(x, np.ndarray):\n",
    "        if x.size > 1:\n",
    "            ax[0, i].plot(x, helper.random_slice(Y, axis=i))\n",
    "            ax[0, i].set_xlabel(x_name)\n",
    "            ax[0, i].set_ylabel(Y_name)\n",
    "            #ax[0, i].set_title(', '.join(['{}={}'.format(name, val) for name, val in ])\n",
    "        else:\n",
    "            ax[0, i].axis('off')\n",
    "    else:\n",
    "        ax[0, i].axis('off')\n",
    "    \n",
    "    # Plot heatmap with other parameters\n",
    "    for j, (x_name_, x_) in enumerate(zip(X_name, X)):\n",
    "        if j > i:\n",
    "            h = ax[1, k].imshow(helper.random_slice(Y, axis=(i, j)),\n",
    "                                cmap=palette,\n",
    "                                aspect='auto',\n",
    "                                origin='lower',\n",
    "                                vmin=Y_range[0],\n",
    "                                vmax=Y_range[1])\n",
    "            ax[1, k].set_xlabel(x_name_)\n",
    "            ax[1, k].set_ylabel(x_name)\n",
    "            k += 1\n",
    "            \n",
    "fig.colorbar(h, ax=ax[1, k-1])\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (behavior)",
   "language": "python",
   "name": "behavior"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
