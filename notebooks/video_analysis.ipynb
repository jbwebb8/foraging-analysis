{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "- [Camera calibration](#Camera-calibration)\n",
    "- [Synchronization](#Synchronization)\n",
    "- [Position tracking](#Position-tracking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cam_calibration\"></a>\n",
    "## Camera calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'googleapiclient' Some Google Drive API methods may not be available.\n"
     ]
    }
   ],
   "source": [
    "# Numerical tools\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Plotting tools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# OS tools\n",
    "import os\n",
    "from tempfile import NamedTemporaryFile\n",
    "import time\n",
    "import subprocess as sp\n",
    "import getpass\n",
    "\n",
    "# File I/O\n",
    "import csv\n",
    "import yaml\n",
    "import glob\n",
    "import imageio\n",
    "\n",
    "# Video tools\n",
    "import moviepy\n",
    "import moviepy.editor\n",
    "\n",
    "# Custom modules\n",
    "import sys\n",
    "sys.path.insert(0, '../python/')\n",
    "import util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = util.GoogleDriveService()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download video file\n",
    "cam_filename = 'webcam_60in_30fps_landscape_dim.mkv'\n",
    "parent_folder = 'fov\n",
    "f = NamedTemporaryFile()\n",
    "file_id = service.get_file_ids(filename=cam_filename,\n",
    "                               unique=True,\n",
    "                               exact_match=True,\n",
    "                               parent=parent_folder)[0]\n",
    "service.download(file_id=file_id,\n",
    "                 chunk_size=1024*1024*100,\n",
    "                 file_object=f);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure distances\n",
    "Note: All videos were taken in 1920 x 1080 resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = moviepy.editor.VideoFileClip(f.name)\n",
    "img = clip.get_frame(0.5)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 12\n",
    "x1 = 915\n",
    "x2 = 1163\n",
    "ppi = (x2 - x1)/d\n",
    "print('ppi: %.2f' % ppi)\n",
    "print('field per pixel: %.4f in' % (1.0/ppi))\n",
    "print('field: %.2f in x %.2f in' % (1920/ppi, 1080/ppi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List calibrations here:\n",
    "\n",
    "\n",
    "cam height (in) | x1 (pixels) | x2 (pixels) | distance (in) | ppi    | field (in) per pixel | field (in x in)\n",
    "--------------- | ----------- | ----------- | ------------- | ------ | ---------------------| ---------------\n",
    "30              | 3           | 546         | 12            | 45.25  | 0.0221               | 42.43 x 23.87\n",
    "60              | 715         | 1013        | 12            | 24.83  | 0.0403               | 77.32 x 43.49\n",
    "71              | 915         | 1163        | 12            | 20.67  | 0.0484               | 92.90 x 52.26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit calibration\n",
    "If we draw the field of view $d$ as a function of camera height $h$, we can pretty easily estimate it as a linear function:\n",
    "\n",
    "$\n",
    "d = \\left ( \\frac{2}{tan(\\theta)} \\right ) h\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit line via least-squares\n",
    "A = np.array([[1, 30],\n",
    "              [1, 60],\n",
    "              [1, 71]])\n",
    "b = np.array([[0.0221],\n",
    "              [0.0403],\n",
    "              [0.0484]])\n",
    "x_hat = np.linalg.inv(A.T.dot(A)).dot(A.T.dot(b))\n",
    "print(x_hat)\n",
    "\n",
    "# Define field of view per pixel as function of camera height\n",
    "d = lambda h: x_hat[0, 0] + x_hat[1, 0]*h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data points\n",
    "plt.scatter(A[:, 1], b)\n",
    "\n",
    "# Plot regression line\n",
    "x = np.linspace(30, 75, num=100)\n",
    "plt.plot(x, d(x), color='black', linestyle='--')\n",
    "\n",
    "plt.xlabel('camera height (in)')\n",
    "plt.ylabel('field width (in) per pixel');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "h = np.linspace(0, 120, num=1000)\n",
    "\n",
    "# Plot field widths vs. camera height\n",
    "ax.plot(h*2.54, 1920*d(h)*2.54, color='black', alpha=0.75, label='width') # cm\n",
    "ax.plot(h*2.54, 1080*d(h)*2.54, color='black', alpha=0.25, label='height') # cm\n",
    "\n",
    "# Plot field width at 2.7 meters (ceiling height)\n",
    "ax.vlines(270, 0.0, 1080*d(270/2.54)*2.54, color='black', alpha=0.25,\n",
    "          linestyle='--', label='max width')\n",
    "ax.hlines(1080*d(270/2.54)*2.54, 0.0, 270, color='black', alpha=0.25,\n",
    "          linestyle='--')\n",
    "\n",
    "ax.set_xlabel('camera height (cm)')\n",
    "ax.set_ylabel('field (cm)')\n",
    "ax.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synchronization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical tools\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Plotting tools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# OS tools\n",
    "import os\n",
    "from tempfile import TemporaryFile\n",
    "import time\n",
    "import subprocess as sp\n",
    "import getpass\n",
    "\n",
    "# Video tools\n",
    "import moviepy\n",
    "import moviepy.editor\n",
    "\n",
    "# Custom modules\n",
    "import sys\n",
    "sys.path.insert(0, '../python/')\n",
    "import util\n",
    "import session\n",
    "import plot\n",
    "import analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Load video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = util.GoogleDriveService()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_dir = '/media/james/data/foraging/linear_track/raw/19-10-03/' # where to download\n",
    "base_filename = 'R002_d50_2019-10-03-1323'\n",
    "cam_filename = base_filename + '_cam-1.mkv' # if comparing to behavior session\n",
    "#cam_filename = base_filename + '.mkv' # if comparing videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow read/write permissions from directory\n",
    "password = getpass.getpass()\n",
    "command = 'sudo -S chmod 777 %s' % media_dir # -S enables input from stdin\n",
    "os.system('echo %s | %s' % (password, command));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download video file\n",
    "with open(media_dir + cam_filename, 'wb') as f:\n",
    "    service.download(filename=cam_filename,\n",
    "                     chunk_size=1024*1024*100,\n",
    "                     file_object=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to mp4 format if not already\n",
    "if not cam_filename.lower().endswith('.mp4'):\n",
    "    new_filename = '.'.join(cam_filename.split('.')[:-1]) + '.mp4'\n",
    "    cmd = ['ffmpeg',\n",
    "           '-i', media_dir + cam_filename,\n",
    "           '-codec', 'copy',\n",
    "           '-copyts',\n",
    "           '-vsync', 'vfr',\n",
    "           media_dir + new_filename]\n",
    "    cam_filename = new_filename\n",
    "    with sp.Popen(cmd) as p:\n",
    "        p.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get frame rate using ffprobe\n",
    "cmd = ['ffprobe',\n",
    "       '-i', media_dir + cam_filename,\n",
    "       '-select_streams', 'v',\n",
    "       '-show_streams',\n",
    "       '-show_entries', 'stream=avg_frame_rate',\n",
    "       '-of', 'csv=p=0']\n",
    "with sp.Popen(cmd, bufsize=100, stdout=sp.PIPE, stderr=sp.PIPE) as p:\n",
    "    p.wait() # waits until process has terminated\n",
    "    s = p.stdout.read(100)\n",
    "    fps = s.decode().split(',')[0].strip(' \\n')\n",
    "    fps = round(float(fps.split('/')[0]) / float(fps.split('/')[1]))\n",
    "    \n",
    "print(fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get start time using ffprobe\n",
    "cmd = ['ffprobe',\n",
    "       '-i', media_dir + cam_filename,\n",
    "       '-select_streams', 'v',\n",
    "       '-show_entries', 'stream=start_time',\n",
    "       '-of', 'csv=p=0']\n",
    "with sp.Popen(cmd, bufsize=100, stdout=sp.PIPE, stderr=sp.PIPE) as p:\n",
    "    p.wait() # waits until process has terminated\n",
    "    s = p.stdout.read(100)\n",
    "    t_start = float(s.decode().strip(' \\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract timestamps\n",
    "# https://superuser.com/questions/841872/how-do-i-extract-the-timestamps-associated-with-frames-ffmpeg-extracts-from-a-vi\n",
    "ts_filename = base_filename + '_ts.csv'\n",
    "cmd = ['ffprobe',\n",
    "       '-i', media_dir + cam_filename,\n",
    "       '-select_streams', 'v',\n",
    "       '-show_frames',\n",
    "       '-show_entries', 'frame=pkt_pts_time',\n",
    "       '-of', 'csv=p=0']\n",
    "with open(media_dir+ts_filename, 'w') as f, \\\n",
    "     sp.Popen(cmd, stdout=f, stderr=sp.PIPE) as p:\n",
    "    p.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load timestamps\n",
    "ts = np.loadtxt(media_dir + ts_filename)\n",
    "assert ts[0] == t_start\n",
    "duration = ts[-1] - ts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frame rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many frames?\n",
    "print('Expected number of frames: {}'.format(int(fps*duration)+1))\n",
    "print('Actual number of frames:   {}'.format(ts.shape[0]))\n",
    "print('Mean interval:             {:.5f}'.format(np.mean(np.diff(ts))))\n",
    "print('Std interval:              {:.5f}'.format(np.std(np.diff(ts))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of instantaneous fps\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "ax[0].plot(ts[:-1]-ts[0], np.diff(ts))\n",
    "ax[1].hist(np.diff(ts))\n",
    "\n",
    "print('Minimum inter-frame duration: %.5f' % np.min(np.diff(ts)))\n",
    "print('Maximum inter-frame duration: %.5f' % np.max(np.diff(ts)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Software timestamps\n",
    "Some quick notes on how `moviepy` works, particularly with grabbing video frames. We can create a `VideoFileClip` object with a local video file to quickly view frames or even embed clips in the notebook. Under the hood, all `Clip` objects use ffmpeg to do the heavy lifting.\n",
    "\n",
    "Every `Clip` object has a `make_frame` function that takes time as an argument and returns the video frame most closely associated with that time. In a `VideoFileClip` object, this method is the `get_frame` method for its associated `FFMPEG_VideoReader` (`self.reader.get_frame`). The `FFMPEG_VideoReader` object serves as an interface between the user and `ffmpeg` by calling commands via the `subprocess` module. To read video frame(s) at certain times, it essentially calls the following methods:\n",
    "\n",
    "`get_frame(t)`: Get the video frame at time `t` in one or two ways. If the video stream at time not too far behind `t`, then call `skip_frames`; otherwise, `initialize` at `t` and `read_frame`.\n",
    "\n",
    "`initialize(t)`: Initialize an `ffmpeg` subprocess that begins streaming video data at time `t` to `stdout`. In other words, it calls an `ffmpeg` command to write video frames not to a file but to `stdout` (which will become clear in a moment). The command is: \n",
    "\n",
    "```ffmpeg -ss <t-1> -i <filename> -ss 1 -loglevel error -f image2pipe -vf scale=<W:H> -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -```\n",
    "\n",
    "where `-ss` before the input file (`-i`) specifies where to set the pointer to begin streaming (in seconds), `-ss` after the input file specifies how much data to ignore before streaming (in seconds), `-f image2pipe` sets the output to be piped, and the trailing `-` to `stdout`, and `-vcodec rawvideo` specifies that the raw data frames should not be re-encoded. For a good discussion of what the `-ss` flag does, see [this post](https://superuser.com/questions/554620/how-to-get-time-stamp-of-closest-keyframe-before-a-given-timestamp-with-ffmpeg) or [this one](https://stackoverflow.com/questions/11688704/ffmpeg-inaccurate-outputs).\n",
    "\n",
    "`read_frame`: This simply reads the expected number of bytes in one image (based on pixel size) from stdout from the process launched in `initialize`; thus it should read the video frame most closely associated with time `t`. The bytes are fed and reshaped into a `numpy` array.\n",
    "\n",
    "`skip_frames`: If the query time `t` is only slightly ahead of the time with which `initialize` was most recently called, then it is more efficient to read through stdout with the current process than to `initialize` a new one at time `t`. So `skip_frames(n)` reads `n` chunks of video frames from stdout, incrementing its pointer accordingly, so that `read_frame` will then read the frame at time `t`.\n",
    "\n",
    "If we are interested in comparing absolute system timestamps, however, we need to know how these frames are being selected with the time inputs. Each frame contains the following metadata (with the command `ffprobe -i <filename> -show_frames`):\n",
    "\n",
    "```\n",
    "[FRAME]\n",
    "media_type=video\n",
    "stream_index=0\n",
    "key_frame=1\n",
    "pkt_pts=2422538728\n",
    "pkt_pts_time=2422538.728000\n",
    "pkt_dts=2422538728\n",
    "pkt_dts_time=2422538.728000\n",
    "best_effort_timestamp=2422538728\n",
    "best_effort_timestamp_time=2422538.728000\n",
    "pkt_duration=33\n",
    "pkt_duration_time=0.033000\n",
    "pkt_pos=27816\n",
    "pkt_size=21693\n",
    "width=1920\n",
    "height=1080\n",
    "pix_fmt=yuvj420p\n",
    "sample_aspect_ratio=1:1\n",
    "pict_type=I\n",
    "coded_picture_number=3\n",
    "display_picture_number=0\n",
    "interlaced_frame=0\n",
    "top_field_first=0\n",
    "repeat_pict=0\n",
    "[/FRAME]\n",
    "```\n",
    "\n",
    "and here is what `ffmpeg` knows about the file:\n",
    "\n",
    "```\n",
    "  Metadata:\n",
    "    encoder         : Guvcview Muxer-2014.04\n",
    "  Duration: 673:25:27.17, start: 2422538.660000, bitrate: 2 kb/s\n",
    "    Stream #0:0(eng): Video: h264 (Constrained Baseline), yuvj420p(pc), 1920x1080 [SAR 1:1 DAR 16:9], 30 fps, 30 tbr, 1k tbn, 60 tbc (default)\n",
    "```\n",
    "\n",
    "The system timestamps (`pkt_pts`) do not start at zero but are absolute (as intended in the change made to `guvcview`). However, `moviepy` (and thus `ffmpeg`) correctly identifies frames by relative time, despite calculating the duration of the video based on absolute time. Therefore, they can't be using these absolute timestamps to seek within the video. Instead, they must be either using the `pkt_duration_time` between frames, making `pkt_pts` relative to the first frame, or, less likely, selecting the index of the frame based on a uniform sampling rate.\n",
    "\n",
    "In any case, I think that it is safe to do the following the check for behavior/video synchronization:\n",
    "1. Get a behavior event (lick, poke, etc.).\n",
    "2. Get the system timestamp associated with the behavior event.\n",
    "3. Find the system timestamp in the video timestamp file closest to this behavior event. (This really isn't necessary, since `moviepy` takes care of that in step 5.)\n",
    "4. Calculate the relative timestamp in the video file by subtracting the timestamp of the first frame from the timestamp in step 3.\n",
    "5. Get the frame associated with the relative timestamp by calling `clip.get_frame`.\n",
    "6. Check if the behavior in step 1 is occurring in the frame.\n",
    "\n",
    "For a nice tutorial about `ffmpeg`, see [here](http://dranger.com/ffmpeg/).\n",
    "\n",
    "**Edit**: We should actually be able to obtain the input to the subprocess called by `reader` by calling `clip.reader.proc.args`. We could then reformat these into a `ffprobe` command to get the timestamps of the frame returned by `clip.get_frame`.\n",
    "\n",
    "**Edit**: Weird. Unlike `ffmpeg`, `ffprobe` cannot seek in the file by relative time by using the `-read_interval` flag, which appears to be analogous to the `-ss` flag in `ffmpeg`. This seems to be due to a difference in optional argument processing between the two. Whereas `ffmpeg` adds the time [relative to the start time](https://gitlab.websupport.sk/peter.kovar/ffmpeg-mvc/blob/master/fftools/ffmpeg_opt.c#L1113-1115), `ffprobe` [does not](https://gitlab.websupport.sk/peter.kovar/ffmpeg-mvc/blob/master/fftools/ffprobe.c#L2345-2356). (Why this causes an issue when [`ebml_read_num`](https://gitlab.websupport.sk/peter.kovar/ffmpeg-mvc/blob/master/libavformat/matroskadec.c#L821-822) is called (indirectly) by [`avformat_seek_file`](https://gitlab.websupport.sk/peter.kovar/ffmpeg-mvc/blob/master/libavformat/utils.c#L2500-2501), I'm not sure.) But the silver lining is that we can use `ffprobe` to get the start time in the file metadata:\n",
    "\n",
    "```shell\n",
    "ffprobe -i <filename> -show_entries stream=start_time -of csv=p=0\n",
    "```\n",
    "\n",
    "and then add this time to the query time in `clip.get_frame` to get the absolute system time. Or, working the other way, we use this start time to determine the query time in step 4 of the above workflow.\n",
    "\n",
    "**Note**: `FFMPEG_VideoReader` grabs the incorrect duration for the video files. The function `ffmpeg_parse_infos` uses regex on the initial `ffmpeg` output (although using `ffprobe` would be better) to search for duration. However, it expects the format HH:MM:SS(.ssssss). If there are more than 99 hours, then it would incorrectly leave off the trailing digits, as is the case with these files (since duration here is just the last timestamp, which is absolute system time). This does not, however, appear to affect performance.\n",
    "\n",
    "**Note**: `ffmpeg` incorrectly seeks for matroska or `mkv` files. Importantly, all files should be remuxed to `mp4` if not already:\n",
    "\n",
    "```shell\n",
    "ffmpeg -i <filename>.mkv -codec copy -copyts -vsync vfr <filename>.mp4\n",
    "```\n",
    "\n",
    "See the appendix for details. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Behavior synchronization\n",
    "Let's test the synchronization between one camera and behavior data collected on the PCB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load behavior session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results directory\n",
    "folder_id = service.get_folder_ids(foldername='R001', \n",
    "                                   exact_match=True, \n",
    "                                   parent='track_task_analysis')\n",
    "\n",
    "# Load data file\n",
    "data_filename = base_filename + '_log.txt'\n",
    "load_fn = lambda x: np.loadtxt(x, delimiter=',')\n",
    "data = util.bytes_to_object(service.download(filename=data_filename),\n",
    "                            ob_type='numpy',\n",
    "                            load_fn=load_fn)\n",
    "\n",
    "# Load params file\n",
    "params_filename = base_filename  + '_params.json'\n",
    "params = util.bytes_to_object(service.download(filename=params_filename),\n",
    "                              ob_type='json')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Session objects\n",
    "sess = session.TTSession(data, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find behavior events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample patch times, uniformly within each patch\n",
    "idx_patch = (sess.get_patch_times()*sess.data['fs']).astype(np.int64) # row in log file\n",
    "t_patch = sess._load_data('t_os')[idx_patch.flatten()].reshape([-1, 2]) # OS clock\n",
    "r = np.random.random(t_patch.shape[0])\n",
    "patch_set = t_patch[:, 0] + np.diff(t_patch, axis=1).squeeze()*r\n",
    "\n",
    "# Sample middle third of interpatches (to avoid confusion entering/exiting patch)\n",
    "t_interpatch = t_patch.flatten()[1:-1].reshape([-1, 2])\n",
    "r = np.random.uniform(0.33, 0.66, size=t_interpatch.shape[0])\n",
    "interpatch_set = t_interpatch[:, 0] + np.diff(t_interpatch, axis=1).squeeze()*r\n",
    "\n",
    "# Get lick times\n",
    "idx_lick = (sess.get_lick_times()*sess.data['fs']).astype(np.int64) # row in log file\n",
    "lick_set = sess._load_data('t_os')[idx_lick.flatten()] # OS clock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find associated video frames\n",
    "More notes on file seeking in `ffprobe`. We want to get the frame number associated with the query times below. Now, interestingly, `ffprobe` correctly seeks (in `mp4` files) with the `read_intervals` flag using *system timestamps*; that is, while `ffmpeg` seeks time in the video relative to the start time (with `-ss`), `ffprobe` seeks in absolute time (again, in `mp4` files, at least). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create VideoFileClip object\n",
    "clip = moviepy.editor.VideoFileClip(media_dir + cam_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find video frame number (long way)\n",
    "def get_frame_index(t_start, t):\n",
    "    # Get frame number using ffprobe\n",
    "    # https://stackoverflow.com/a/13332300/8066298\n",
    "    cmd = ['ffprobe',\n",
    "           '-i', media_dir + cam_filename,\n",
    "           '-select_streams', 'v',\n",
    "           '-read_intervals', '{:.6f}%{:.6f}'.format(t_start, t),\n",
    "           '-show_frames',\n",
    "           '-show_entries', 'frame=pkt_pts_time',\n",
    "           '-of', 'csv=p=0']\n",
    "    with sp.Popen(cmd, bufsize=100, stdout=sp.PIPE, stderr=sp.PIPE) as p:\n",
    "        s = sp.check_output(['wc', '-l'], stdin=p.stdout) # count number of lines\n",
    "        p.wait() # waits until process has terminated\n",
    "        n_frame = int(s.decode().strip(' \\n'))\n",
    "    \n",
    "    return n_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_samples = 50\n",
    "t_range = [-1, -1]\n",
    "\n",
    "ncols = 3\n",
    "nrows = n_samples // ncols + (n_samples % ncols > 0)\n",
    "fig, ax = plt.subplots(nrows, ncols, figsize=(5*ncols, 3*nrows))\n",
    "\n",
    "sample_set = [patch_set, interpatch_set, lick_set]\n",
    "sample_ids = ['patch', 'interpatch', 'lick']\n",
    "idx = np.random.choice(np.arange(len(sample_set)), size=n_samples)\n",
    "                \n",
    "if t_range[0] == -1:\n",
    "    t_range[0] = -np.inf\n",
    "if t_range[1] == -1:\n",
    "    t_range[1] = np.inf\n",
    "    \n",
    "for i, n in enumerate(idx):\n",
    "    # Sample event timestamp\n",
    "    t = np.inf\n",
    "    while not ((t-t_start > t_range[0]) and (t-t_start < t_range[1])):\n",
    "        set_n = sample_set[n]\n",
    "        t = float(np.random.choice(set_n, size=1))\n",
    "    \n",
    "    # Get corresponding video frame\n",
    "    frame = clip.get_frame(t - t_start)\n",
    "    #frame = get_frame(clip, t - t_start, i_interval=10.0)\n",
    "    \n",
    "    # Get frame number\n",
    "    #n_frame = get_frame_index(t_start, t)\n",
    "    n_frame = int((t-t_start)*fps) + 1 # 1-based indexing\n",
    "    \n",
    "    \n",
    "    # Plot frame\n",
    "    j = i // ncols\n",
    "    k = i % ncols\n",
    "    ax_ = ax[j, k]\n",
    "    ax_.imshow(frame)\n",
    "    ax_.set_title('{} event\\ntime {:.2f}\\nframe {}'.format(sample_ids[n], t-t_start, n_frame))\n",
    "    ax_.set_xticks([])\n",
    "    ax_.set_yticks([])\n",
    "\n",
    "# Turn off unused axes\n",
    "rem = (ncols - n_samples % ncols) % ncols\n",
    "for i in range(1, rem+1):\n",
    "    ax[-1, -i].axis('off')\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera synchronization\n",
    "If we need to use multiple webcams to cover the entire FOV, will they remain synchronized across multiple `guvcview` subprocesses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All video files should be in media_dir\n",
    "cam_filenames = ['webcam_60min_12-05-19_1.mp4',\n",
    "                 'webcam_60min_12-05-19_2.mp4']\n",
    "ts_filenames = ['webcam_60min_12-05-19_1_ts.csv',\n",
    "                'webcam_60min_12-05-19_2_ts.csv']\n",
    "num_cams = len(cam_filenames)\n",
    "\n",
    "# Create VideoFileClip objects\n",
    "clips = []\n",
    "ts = []\n",
    "for cam_filename, ts_filename in zip(cam_filenames, ts_filenames):\n",
    "    clips.append(moviepy.editor.VideoFileClip(media_dir + cam_filename))\n",
    "    ts.append(np.loadtxt(media_dir + ts_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot images from all cameras at same system time\n",
    "n_samples = 3\n",
    "crop = True\n",
    "crop_width = [700, 1220]\n",
    "crop_height = [300, 780]\n",
    "ncols = len(cam_filenames)\n",
    "nrows = n_samples\n",
    "fig, ax = plt.subplots(nrows, ncols, figsize=(10*ncols, 5*nrows))\n",
    "\n",
    "# Select random system times\n",
    "t_rand = np.random.uniform(max([ts_[0] for ts_ in ts]), \n",
    "                           min([ts_[-1] for ts_ in ts]),\n",
    "                           size=n_samples)\n",
    "\n",
    "for i, t in enumerate(t_rand):   \n",
    "    for j, clip in enumerate(clips):\n",
    "        # Get corresponding video frame\n",
    "        t_clip = t - ts[j][0]\n",
    "        frame = clip.get_frame(t_clip)\n",
    "        if crop:\n",
    "            frame = frame[crop_height[0]:crop_height[1],\n",
    "                          crop_width[0]:crop_width[1]]\n",
    "        \n",
    "        # Plot frame\n",
    "        ax_ = ax[i, j]\n",
    "        ax_.imshow(frame)\n",
    "        ax_.set_ylabel('system time {:.2f} (elapse time {:.2f})'.format(t, t_clip))\n",
    "        ax_.set_xticks([])\n",
    "        ax_.set_yticks([])\n",
    "\n",
    "# Format plot\n",
    "for j in range(len(clips)):\n",
    "    ax[0, j].set_title('Camera {}'.format(j))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Position tracking\n",
    "We'll use DeepLabCut to track the animal's position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import deeplabcut as dlc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'freely-moving'\n",
    "experimenter = 'james'\n",
    "project_dir = '../dlc'\n",
    "video_dir = '/media/james/data/foraging/linear_track/dlc_videos/'\n",
    "video_filepaths = ['/'.join([video_dir, f]) for f in os.listdir(video_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created \"/home/james/Documents/Projects/foraging/code/foraging-analysis/dlc/freely-moving-james-2020-05-20/videos\"\n",
      "Created \"/home/james/Documents/Projects/foraging/code/foraging-analysis/dlc/freely-moving-james-2020-05-20/labeled-data\"\n",
      "Created \"/home/james/Documents/Projects/foraging/code/foraging-analysis/dlc/freely-moving-james-2020-05-20/training-datasets\"\n",
      "Created \"/home/james/Documents/Projects/foraging/code/foraging-analysis/dlc/freely-moving-james-2020-05-20/dlc-models\"\n",
      "Creating the symbolic link of the video\n",
      "Created the symlink of /media/james/data/foraging/linear_track/dlc_videos/R002_d40_2019-09-19-1128_cam-1.mp4 to /home/james/Documents/Projects/foraging/code/foraging-analysis/dlc/freely-moving-james-2020-05-20/videos/R002_d40_2019-09-19-1128_cam-1.mp4\n",
      "Created the symlink of /media/james/data/foraging/linear_track/dlc_videos/R001_d35_2019-09-12-1211_cam-1.mp4 to /home/james/Documents/Projects/foraging/code/foraging-analysis/dlc/freely-moving-james-2020-05-20/videos/R001_d35_2019-09-12-1211_cam-1.mp4\n",
      "Created the symlink of /media/james/data/foraging/linear_track/dlc_videos/R004_d60_2019-10-17-1127_cam-1.mp4 to /home/james/Documents/Projects/foraging/code/foraging-analysis/dlc/freely-moving-james-2020-05-20/videos/R004_d60_2019-10-17-1127_cam-1.mp4\n",
      "Created the symlink of /media/james/data/foraging/linear_track/dlc_videos/R002_d51_2019-10-04-1305_cam-1.mp4 to /home/james/Documents/Projects/foraging/code/foraging-analysis/dlc/freely-moving-james-2020-05-20/videos/R002_d51_2019-10-04-1305_cam-1.mp4\n",
      "Created the symlink of /media/james/data/foraging/linear_track/dlc_videos/R001_d46_2019-09-27-1436_cam-1.mp4 to /home/james/Documents/Projects/foraging/code/foraging-analysis/dlc/freely-moving-james-2020-05-20/videos/R001_d46_2019-09-27-1436_cam-1.mp4\n",
      "Created the symlink of /media/james/data/foraging/linear_track/dlc_videos/R003_d55_2019-10-11-1138_cam-1.mp4 to /home/james/Documents/Projects/foraging/code/foraging-analysis/dlc/freely-moving-james-2020-05-20/videos/R003_d55_2019-10-11-1138_cam-1.mp4\n",
      "Created the symlink of /media/james/data/foraging/linear_track/dlc_videos/R004_d50_2019-10-03-1240_cam-1.mp4 to /home/james/Documents/Projects/foraging/code/foraging-analysis/dlc/freely-moving-james-2020-05-20/videos/R004_d50_2019-10-03-1240_cam-1.mp4\n",
      "Created the symlink of /media/james/data/foraging/linear_track/dlc_videos/R003_d41_2019-09-20-1455_cam-1.mp4 to /home/james/Documents/Projects/foraging/code/foraging-analysis/dlc/freely-moving-james-2020-05-20/videos/R003_d41_2019-09-20-1455_cam-1.mp4\n",
      "/home/james/Documents/Projects/foraging/code/foraging-analysis/dlc/freely-moving-james-2020-05-20/videos/R002_d40_2019-09-19-1128_cam-1.mp4\n",
      "/home/james/Documents/Projects/foraging/code/foraging-analysis/dlc/freely-moving-james-2020-05-20/videos/R001_d35_2019-09-12-1211_cam-1.mp4\n",
      "/home/james/Documents/Projects/foraging/code/foraging-analysis/dlc/freely-moving-james-2020-05-20/videos/R004_d60_2019-10-17-1127_cam-1.mp4\n",
      "/home/james/Documents/Projects/foraging/code/foraging-analysis/dlc/freely-moving-james-2020-05-20/videos/R002_d51_2019-10-04-1305_cam-1.mp4\n",
      "/home/james/Documents/Projects/foraging/code/foraging-analysis/dlc/freely-moving-james-2020-05-20/videos/R001_d46_2019-09-27-1436_cam-1.mp4\n",
      "/home/james/Documents/Projects/foraging/code/foraging-analysis/dlc/freely-moving-james-2020-05-20/videos/R003_d55_2019-10-11-1138_cam-1.mp4\n",
      "/home/james/Documents/Projects/foraging/code/foraging-analysis/dlc/freely-moving-james-2020-05-20/videos/R004_d50_2019-10-03-1240_cam-1.mp4\n",
      "/home/james/Documents/Projects/foraging/code/foraging-analysis/dlc/freely-moving-james-2020-05-20/videos/R003_d41_2019-09-20-1455_cam-1.mp4\n",
      "Generated \"/home/james/Documents/Projects/foraging/code/foraging-analysis/dlc/freely-moving-james-2020-05-20/config.yaml\"\n",
      "\n",
      "A new project with name freely-moving-james-2020-05-20 is created at /home/james/Documents/Projects/foraging/code/foraging-analysis/dlc and a configurable file (config.yaml) is stored there. Change the parameters in this file to adapt to your project's needs.\n",
      " Once you have changed the configuration file, use the function 'extract_frames' to select frames for labeling.\n",
      ". [OPTIONAL] Use the function 'add_new_videos' to add new videos to your project (at any stage).\n"
     ]
    }
   ],
   "source": [
    "# If creating new project\n",
    "config_path = dlc.create_new_project(task,\n",
    "                                     experimenter,\n",
    "                                     video_filepaths,\n",
    "                                     working_directory=project_dir,\n",
    "                                     copy_videos=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If modifying existing project\n",
    "config_path = '{}/freely-moving-james-2019-10-03/config.yaml'.format(project_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we need to modify the config file found at `config_path`. This will determine how the next steps will be processed. See [here](https://github.com/AlexEMG/DeepLabCut/blob/master/docs/functionDetails.md#a-create-a-new-project) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract frames\n",
    "DLC gives us the choice of either 1) automatically extracting frames for the training, or 2) manually selecting frames for the training set. Auto-extraction has two methods: 1) sample random frames uniformly across the video, or 2) sample random frames from clusters generated by applying k-means to vectorized images. The latter method has two drawbacks: 1) computationally slow (vectorizes images and then runs k-means), and 2) probably inaccurate (mice are such small part of the image that I doubt k-means will properly segregate images)).\n",
    "\n",
    "I see two potential ways of generating training data.\n",
    "- Automatic uniform: Use the DLC auto-extract feature to sample the session uniformly. While this will probably generate more unpoked than poked frames, those are probably harder and certainly much more variable, so I think it's probably fine.\n",
    "- Manual: Select frames manually using the DLC GUI. We can use the frame numbers above as guidance for events to use.\n",
    "\n",
    "By the way, the reason that we have to seek by frame number instead of timestamp is that the [DLC GUI](https://github.com/AlexEMG/DeepLabCut/blob/master/deeplabcut/generate_training_dataset/frame_extraction_toolbox.py#L370-L371) uses an `opencv.VideoCapture` object to seek in the video file, which apparently uses [frame number](https://docs.opencv.org/2.4/modules/highgui/doc/reading_and_writing_images_and_video.html#videocapture-set) instead of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auto extraction\n",
    "Randomly sample frames uniformly across session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file read successfully.\n",
      "Do you want to extract (perhaps additional) frames for video: /media/james/data/foraging/linear_track/dlc_videos/R002_d40_2019-09-19-1128_cam-1.mp4 ?\n",
      "yes/noyes\n",
      "Extracting frames based on uniform ...\n",
      "Uniformly extracting of frames from 90.77  seconds to 1724.67  seconds.\n",
      "Do you want to extract (perhaps additional) frames for video: /media/james/data/foraging/linear_track/dlc_videos/R001_d35_2019-09-12-1211_cam-1.mp4 ?\n",
      "yes/noyes\n",
      "Extracting frames based on uniform ...\n",
      "Uniformly extracting of frames from 90.41  seconds to 1717.7  seconds.\n",
      "Do you want to extract (perhaps additional) frames for video: /media/james/data/foraging/linear_track/dlc_videos/R004_d60_2019-10-17-1127_cam-1.mp4 ?\n",
      "yes/noyes\n",
      "Extracting frames based on uniform ...\n",
      "Uniformly extracting of frames from 92.92  seconds to 1765.52  seconds.\n",
      "Do you want to extract (perhaps additional) frames for video: /media/james/data/foraging/linear_track/dlc_videos/R002_d51_2019-10-04-1305_cam-1.mp4 ?\n",
      "yes/noyes\n",
      "Extracting frames based on uniform ...\n",
      "Uniformly extracting of frames from 89.28  seconds to 1696.26  seconds.\n",
      "Do you want to extract (perhaps additional) frames for video: /media/james/data/foraging/linear_track/dlc_videos/R001_d46_2019-09-27-1436_cam-1.mp4 ?\n",
      "yes/noyes\n",
      "Extracting frames based on uniform ...\n",
      "Uniformly extracting of frames from 99.51  seconds to 1890.6  seconds.\n",
      "Do you want to extract (perhaps additional) frames for video: /media/james/data/foraging/linear_track/dlc_videos/R003_d55_2019-10-11-1138_cam-1.mp4 ?\n",
      "yes/noyes\n",
      "Extracting frames based on uniform ...\n",
      "Uniformly extracting of frames from 89.89  seconds to 1707.89  seconds.\n",
      "Do you want to extract (perhaps additional) frames for video: /media/james/data/foraging/linear_track/dlc_videos/R004_d50_2019-10-03-1240_cam-1.mp4 ?\n",
      "yes/noyes\n",
      "Extracting frames based on uniform ...\n",
      "Uniformly extracting of frames from 93.71  seconds to 1780.56  seconds.\n",
      "Do you want to extract (perhaps additional) frames for video: /media/james/data/foraging/linear_track/dlc_videos/R003_d41_2019-09-20-1455_cam-1.mp4 ?\n",
      "yes/noyes\n",
      "Extracting frames based on uniform ...\n",
      "Uniformly extracting of frames from 103.73  seconds to 1970.78  seconds.\n",
      "\n",
      "Frames were selected.\n",
      "You can now label the frames using the function 'label_frames' (if you extracted enough frames for all videos).\n"
     ]
    }
   ],
   "source": [
    "dlc.extract_frames(config_path, 'automatic', 'uniform', crop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual extraction\n",
    "Here, we can use the DLC GUI to select and crop frames (particularly using the frame numbers shown above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.extract_frames(config_path, 'manual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label frames\n",
    "Make sure that the config file is properly configured by applying labels to training set. We should probably choose a few points on the mice to test the robustness of the network to different body features in the videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.label_frames(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.check_labels(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dlc.create_training_dataset.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dlc.create_training_dataset(config_path, \n",
    "                            num_shuffles=1, \n",
    "                            windows2linux=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit the network hyperparameters in `pose_cfg.yaml` configuration file generated under `dlc-models` before proceeding to the `train_network` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dlc.train_network.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.train_network(config_path,\n",
    "                  shuffle=1,\n",
    "                  gputouse=0,\n",
    "                  max_snapshots_to_keep=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get config data\n",
    "with open(config_path, 'r') as f:\n",
    "    cfg = yaml.safe_load(f) # prevents arbitrary code execution\n",
    "model_name = 'freely-movingOct3-trainset95shuffle1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Images from training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dlc.evaluate_network(config_path,\n",
    "                     plotting=True,\n",
    "                     gputouse=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: It may be easier to use the native image viewer to scroll through the images than looking at the (small) plots below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load frames\n",
    "frame_dir = '{}/evaluation-results/iteration-{}/{}/'.format(cfg['project_path'], cfg['iteration'], model_name)\n",
    "frames = [imageio.imread(f) for f in glob.glob(frame_dir + '**/*.png', recursive=True)]\n",
    "\n",
    "# Plot frames\n",
    "num_frames = 10\n",
    "ncols = 2\n",
    "nrows = num_frames // ncols + (num_frames % ncols > 0)\n",
    "fig, ax = plt.subplots(nrows, ncols, figsize=(5*ncols, 5*nrows))\n",
    "\n",
    "idx = np.random.choice(np.arange(len(frames)), size=num_frames, replace=False)\n",
    "for i, n in enumerate(idx):\n",
    "    # Plot frame\n",
    "    j = i // ncols\n",
    "    k = i % ncols\n",
    "    ax_ = ax[j, k]\n",
    "    ax_.imshow(frames[n])\n",
    "    ax_.set_xticks([])\n",
    "    ax_.set_yticks([])\n",
    "\n",
    "# Turn off unused axes\n",
    "rem = (ncols - num_frames % ncols) % ncols\n",
    "for i in range(1, rem+1):\n",
    "    ax[-1, -i].axis('off')\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Novel videos\n",
    "Here, we will extract position from novel behavior videos using the network. Then we will plot various forms of the predicted position based on simple algorithms, such as:\n",
    "- raw position\n",
    "- smoothed position\n",
    "- averaged position (between head and tail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "video_filepaths = ['/media/james/data/foraging/linear_track/raw/19-09-25/R003_d44_2019-09-25-1437_v.mp4',\n",
    "                   '/media/james/data/foraging/linear_track/raw/19-10-03/R002_d50_2019-10-03-1323_v.mp4',\n",
    "                   '/media/james/data/foraging/linear_track/raw/19-10-16/R001_d59_2019-10-16-1140_v.mp4']\n",
    "results_dir = '{}/evaluation-results/iteration-{}/{}'.format(cfg['project_path'], cfg['iteration'], model_name)\n",
    "#print(dlc.analyze_videos.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.analyze_videos(config_path,\n",
    "                   video_filepaths,\n",
    "                   videotype='mp4',\n",
    "                   gputouse=0,\n",
    "                   save_as_csv=True,\n",
    "                   destfolder=results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of videos to be annotated\n",
    "video_filenames = ['/media/james/data/foraging/linear_track/raw/19-09-25/R003_d44_2019-09-25-1437_v.mp4',\n",
    "                   '/media/james/data/foraging/linear_track/raw/19-10-03/R002_d50_2019-10-03-1323_v.mp4',\n",
    "                   '/media/james/data/foraging/linear_track/raw/19-10-16/R001_d59_2019-10-16-1140_v.mp4']\n",
    "pos_filenames = ['/'.join([results_dir, 'R003_d44_2019-09-25-1437_vDeepCut_resnet50_freely-movingOct3shuffle1_1030000.csv']),\n",
    "                 '/'.join([results_dir, 'R002_d50_2019-10-03-1323_vDeepCut_resnet50_freely-movingOct3shuffle1_1030000.csv']),\n",
    "                 '/'.join([results_dir, 'R001_d59_2019-10-16-1140_vDeepCut_resnet50_freely-movingOct3shuffle1_1030000.csv'])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Smoothing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading position data in /home/james/Documents/Projects/foraging/code/foraging-analysis/dlc/freely-moving/freely-moving-james-2019-10-03/evaluation-results/iteration-0/freely-movingOct3-trainset95shuffle1/R003_d44_2019-09-25-1437_vDeepCut_resnet50_freely-movingOct3shuffle1_1030000.csv...\n",
      "Column headers:\n",
      "scorer DeepCut_resnet50_freely-movingOct3shuffle1_1030000 DeepCut_resnet50_freely-movingOct3shuffle1_1030000 DeepCut_resnet50_freely-movingOct3shuffle1_1030000 DeepCut_resnet50_freely-movingOct3shuffle1_1030000 DeepCut_resnet50_freely-movingOct3shuffle1_1030000 DeepCut_resnet50_freely-movingOct3shuffle1_1030000\n",
      "bodyparts head head head tail tail tail\n",
      "coords x y likelihood x y likelihood\n",
      "Shape: (56416, 7)\n"
     ]
    }
   ],
   "source": [
    "# Load csv data\n",
    "pos_file = pos_filenames[0]\n",
    "print('Loading position data in {}...'.format(pos_file))\n",
    "with open(pos_file, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    print('Column headers:')\n",
    "    for i in range(3):\n",
    "        text = next(reader, None)\n",
    "        print(' '.join(text))\n",
    "pos = np.loadtxt(pos_file, skiprows=3, delimiter=',')\n",
    "print('Shape:', pos.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_position(pos, thresh=0.99):\n",
    "    pos_ = np.empty([pos.shape[0], 2, 2])\n",
    "    pos_[:, :, :] = np.nan\n",
    "\n",
    "    # Step 1: Get all high-confidence values for head\n",
    "    idx_head = (pos[:, 3] >= thresh)\n",
    "    pos_[idx_head, 0, 0] = pos[idx_head, 1]\n",
    "    pos_[idx_head, 1, 0] = pos[idx_head, 2]\n",
    "\n",
    "    # Step 2: Get all high-confidence values for tail\n",
    "    idx_tail = (pos[:, 6] >= thresh)\n",
    "    pos_[idx_tail, 0, 1] = pos[idx_tail, 4]\n",
    "    pos_[idx_tail, 1, 1] = pos[idx_tail, 5]\n",
    "\n",
    "    # Step 3: Combine head and tail data (averaging when have both)\n",
    "    pos_ = np.nanmean(pos_, axis=2)\n",
    "\n",
    "    # Step 4: Smooth to avoid jitteriness\n",
    "    for i in range(pos_.shape[1]):\n",
    "        pos_[:, i] = helper.med_filt(pos_[:, i], n=15, ignore_nan=True)\n",
    "\n",
    "    # Step 5: Fill in remaining NaNs with linear interpolation\n",
    "    for i in range(pos_.shape[1]):\n",
    "        idx_nan = np.isnan(pos_[:, i])\n",
    "        pos_[idx_nan, i] = np.interp(np.argwhere(idx_nan).flatten(),\n",
    "                                     np.argwhere(~idx_nan).flatten(),\n",
    "                                     pos_[~idx_nan, i])\n",
    "        \n",
    "    return pos_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc8c0a67240>,\n",
       " <matplotlib.lines.Line2D at 0x7fc8c0a67390>]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(preprocess_position(pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Annotate videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No preprocessed data\n",
    "def annotate(n, ax, pos, thresh=0.90):\n",
    "    # Placeholder\n",
    "    parts_visible = 0\n",
    "    mean = np.array([0.0, 0.0])\n",
    "    \n",
    "    # Annotate head\n",
    "    if pos[n, 3] > thresh:\n",
    "        xy = np.array([pos[n, 1], pos[n, 2]])\n",
    "        circle = plt.Circle(xy, radius=10, color='red')\n",
    "        ax.add_artist(circle)\n",
    "        mean += xy\n",
    "        parts_visible += 1\n",
    "    \n",
    "    # Annotate tail\n",
    "    if pos[n, 6] > thresh:\n",
    "        xy = np.array([pos[n, 4], pos[n, 5]])\n",
    "        circle = plt.Circle(xy, radius=10, color='blue')\n",
    "        ax.add_artist(circle)\n",
    "        mean += xy\n",
    "        parts_visible += 1\n",
    "        \n",
    "    # Plot mean\n",
    "    if parts_visible > 0:\n",
    "        circle = plt.Circle(mean/parts_visible, radius=10, color='green')\n",
    "        ax.add_artist(circle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessed data\n",
    "def annotate(n, ax, pos, **kwargs):\n",
    "    xy = np.array([pos[n, 0], pos[n, 1]])\n",
    "    circle = plt.Circle(xy, radius=10, color='green')\n",
    "    ax.add_artist(circle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading position data in /home/james/Documents/Projects/foraging/code/foraging-analysis/dlc/freely-moving/freely-moving-james-2019-10-03/evaluation-results/iteration-0/freely-movingOct3-trainset95shuffle1/R003_d44_2019-09-25-1437_vDeepCut_resnet50_freely-movingOct3shuffle1_1030000.csv...\n",
      "Column headers:\n",
      "scorer DeepCut_resnet50_freely-movingOct3shuffle1_1030000 DeepCut_resnet50_freely-movingOct3shuffle1_1030000 DeepCut_resnet50_freely-movingOct3shuffle1_1030000 DeepCut_resnet50_freely-movingOct3shuffle1_1030000 DeepCut_resnet50_freely-movingOct3shuffle1_1030000 DeepCut_resnet50_freely-movingOct3shuffle1_1030000\n",
      "bodyparts head head head tail tail tail\n",
      "coords x y likelihood x y likelihood\n",
      "Shape: (56416, 7)\n",
      "Starting to annotate video in /media/james/data/foraging/linear_track/raw/19-09-25/R003_d44_2019-09-25-1437_v.mp4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process 240.0-300.0 seconds:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../python/util.py\", line 1234, in _process_chunk\n",
      "    raise UserWarning('Some frames may be skipped in chunk {}.'.format(n))\n",
      "UserWarning: Some frames may be skipped in chunk 4.\n",
      "Process 180.0-240.0 seconds:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../python/util.py\", line 1234, in _process_chunk\n",
      "    raise UserWarning('Some frames may be skipped in chunk {}.'.format(n))\n",
      "UserWarning: Some frames may be skipped in chunk 3.\n",
      "Process 300.0-360.0 seconds:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../python/util.py\", line 1234, in _process_chunk\n",
      "    raise UserWarning('Some frames may be skipped in chunk {}.'.format(n))\n",
      "UserWarning: Some frames may be skipped in chunk 5.\n",
      "Process 720.0-780.0 seconds:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../python/util.py\", line 1234, in _process_chunk\n",
      "    raise UserWarning('Some frames may be skipped in chunk {}.'.format(n))\n",
      "UserWarning: Some frames may be skipped in chunk 12.\n",
      "Process 900.0-960.0 seconds:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../python/util.py\", line 1234, in _process_chunk\n",
      "    raise UserWarning('Some frames may be skipped in chunk {}.'.format(n))\n",
      "UserWarning: Some frames may be skipped in chunk 15.\n",
      "Process 780.0-840.0 seconds:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../python/util.py\", line 1234, in _process_chunk\n",
      "    raise UserWarning('Some frames may be skipped in chunk {}.'.format(n))\n",
      "UserWarning: Some frames may be skipped in chunk 13.\n",
      "Process 840.0-900.0 seconds:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../python/util.py\", line 1234, in _process_chunk\n",
      "    raise UserWarning('Some frames may be skipped in chunk {}.'.format(n))\n",
      "UserWarning: Some frames may be skipped in chunk 14.\n",
      "Process 1320.0-1380.0 seconds:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../python/util.py\", line 1234, in _process_chunk\n",
      "    raise UserWarning('Some frames may be skipped in chunk {}.'.format(n))\n",
      "UserWarning: Some frames may be skipped in chunk 22.\n",
      "Process 1260.0-1320.0 seconds:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../python/util.py\", line 1234, in _process_chunk\n",
      "    raise UserWarning('Some frames may be skipped in chunk {}.'.format(n))\n",
      "UserWarning: Some frames may be skipped in chunk 21.\n",
      "Process 1860.0-1920.0 seconds:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../python/util.py\", line 1218, in _process_chunk\n",
      "    fig = self._annotate_frame(n_frame, frame)\n",
      "  File \"../python/util.py\", line 1262, in _annotate_frame\n",
      "    self._annotate_fn(n_frame, ax, **self._annotate_kwargs)\n",
      "  File \"<ipython-input-136-e81b74d51e50>\", line 3, in annotate\n",
      "    xy = np.array([pos[n, 0], pos[n, 1]])\n",
      "IndexError: index 56416 is out of bounds for axis 0 with size 56416\n",
      "Process 1800.0-1860.0 seconds:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../python/util.py\", line 1234, in _process_chunk\n",
      "    raise UserWarning('Some frames may be skipped in chunk {}.'.format(n))\n",
      "UserWarning: Some frames may be skipped in chunk 30.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 4664.25 seconds.\n",
      "\n",
      "Loading position data in /home/james/Documents/Projects/foraging/code/foraging-analysis/dlc/freely-moving/freely-moving-james-2019-10-03/evaluation-results/iteration-0/freely-movingOct3-trainset95shuffle1/R002_d50_2019-10-03-1323_vDeepCut_resnet50_freely-movingOct3shuffle1_1030000.csv...\n",
      "Column headers:\n",
      "scorer DeepCut_resnet50_freely-movingOct3shuffle1_1030000 DeepCut_resnet50_freely-movingOct3shuffle1_1030000 DeepCut_resnet50_freely-movingOct3shuffle1_1030000 DeepCut_resnet50_freely-movingOct3shuffle1_1030000 DeepCut_resnet50_freely-movingOct3shuffle1_1030000 DeepCut_resnet50_freely-movingOct3shuffle1_1030000\n",
      "bodyparts head head head tail tail tail\n",
      "coords x y likelihood x y likelihood\n",
      "Shape: (53537, 7)\n",
      "Starting to annotate video in /media/james/data/foraging/linear_track/raw/19-10-03/R002_d50_2019-10-03-1323_v.mp4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process 240.0-300.0 seconds:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../python/util.py\", line 1234, in _process_chunk\n",
      "    raise UserWarning('Some frames may be skipped in chunk {}.'.format(n))\n",
      "UserWarning: Some frames may be skipped in chunk 4.\n",
      "Process 300.0-360.0 seconds:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../python/util.py\", line 1234, in _process_chunk\n",
      "    raise UserWarning('Some frames may be skipped in chunk {}.'.format(n))\n",
      "UserWarning: Some frames may be skipped in chunk 5.\n",
      "Process 360.0-420.0 seconds:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../python/util.py\", line 1234, in _process_chunk\n",
      "    raise UserWarning('Some frames may be skipped in chunk {}.'.format(n))\n",
      "UserWarning: Some frames may be skipped in chunk 6.\n",
      "Process 780.0-840.0 seconds:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../python/util.py\", line 1234, in _process_chunk\n",
      "    raise UserWarning('Some frames may be skipped in chunk {}.'.format(n))\n",
      "UserWarning: Some frames may be skipped in chunk 13.\n",
      "Process 960.0-1020.0 seconds:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../python/util.py\", line 1234, in _process_chunk\n",
      "    raise UserWarning('Some frames may be skipped in chunk {}.'.format(n))\n",
      "UserWarning: Some frames may be skipped in chunk 16.\n",
      "Process 840.0-900.0 seconds:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../python/util.py\", line 1234, in _process_chunk\n",
      "    raise UserWarning('Some frames may be skipped in chunk {}.'.format(n))\n",
      "UserWarning: Some frames may be skipped in chunk 14.\n",
      "Process 900.0-960.0 seconds:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../python/util.py\", line 1234, in _process_chunk\n",
      "    raise UserWarning('Some frames may be skipped in chunk {}.'.format(n))\n",
      "UserWarning: Some frames may be skipped in chunk 15.\n",
      "Process 1380.0-1440.0 seconds:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../python/util.py\", line 1234, in _process_chunk\n",
      "    raise UserWarning('Some frames may be skipped in chunk {}.'.format(n))\n",
      "UserWarning: Some frames may be skipped in chunk 23.\n",
      "Process 1320.0-1380.0 seconds:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../python/util.py\", line 1234, in _process_chunk\n",
      "    raise UserWarning('Some frames may be skipped in chunk {}.'.format(n))\n",
      "UserWarning: Some frames may be skipped in chunk 22.\n",
      "Process 1740.0-1800.0 seconds:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../python/util.py\", line 1218, in _process_chunk\n",
      "    fig = self._annotate_frame(n_frame, frame)\n",
      "  File \"../python/util.py\", line 1259, in _annotate_frame\n",
      "    ax.imshow(frame)\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/site-packages/matplotlib/__init__.py\", line 1810, in inner\n",
      "    return func(ax, *args, **kwargs)\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/site-packages/matplotlib/axes/_axes.py\", line 5494, in imshow\n",
      "    im.set_data(X)\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/site-packages/matplotlib/image.py\", line 634, in set_data\n",
      "    raise TypeError(\"Image data cannot be converted to float\")\n",
      "TypeError: Image data cannot be converted to float\n",
      "Process 1500.0-1560.0 seconds:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../python/util.py\", line 1234, in _process_chunk\n",
      "    raise UserWarning('Some frames may be skipped in chunk {}.'.format(n))\n",
      "UserWarning: Some frames may be skipped in chunk 25.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 4016.29 seconds.\n",
      "\n",
      "Loading position data in /home/james/Documents/Projects/foraging/code/foraging-analysis/dlc/freely-moving/freely-moving-james-2019-10-03/evaluation-results/iteration-0/freely-movingOct3-trainset95shuffle1/R001_d59_2019-10-16-1140_vDeepCut_resnet50_freely-movingOct3shuffle1_1030000.csv...\n",
      "Column headers:\n",
      "scorer DeepCut_resnet50_freely-movingOct3shuffle1_1030000 DeepCut_resnet50_freely-movingOct3shuffle1_1030000 DeepCut_resnet50_freely-movingOct3shuffle1_1030000 DeepCut_resnet50_freely-movingOct3shuffle1_1030000 DeepCut_resnet50_freely-movingOct3shuffle1_1030000 DeepCut_resnet50_freely-movingOct3shuffle1_1030000\n",
      "bodyparts head head head tail tail tail\n",
      "coords x y likelihood x y likelihood\n",
      "Shape: (53300, 7)\n",
      "Starting to annotate video in /media/james/data/foraging/linear_track/raw/19-10-16/R001_d59_2019-10-16-1140_v.mp4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process 0.0-60.0 seconds:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../python/util.py\", line 1234, in _process_chunk\n",
      "    raise UserWarning('Some frames may be skipped in chunk {}.'.format(n))\n",
      "UserWarning: Some frames may be skipped in chunk 0.\n",
      "Process 60.0-120.0 seconds:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../python/util.py\", line 1234, in _process_chunk\n",
      "    raise UserWarning('Some frames may be skipped in chunk {}.'.format(n))\n",
      "UserWarning: Some frames may be skipped in chunk 1.\n",
      "Process 480.0-540.0 seconds:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../python/util.py\", line 1234, in _process_chunk\n",
      "    raise UserWarning('Some frames may be skipped in chunk {}.'.format(n))\n",
      "UserWarning: Some frames may be skipped in chunk 8.\n",
      "Process 540.0-600.0 seconds:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../python/util.py\", line 1234, in _process_chunk\n",
      "    raise UserWarning('Some frames may be skipped in chunk {}.'.format(n))\n",
      "UserWarning: Some frames may be skipped in chunk 9.\n",
      "Process 600.0-660.0 seconds:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../python/util.py\", line 1234, in _process_chunk\n",
      "    raise UserWarning('Some frames may be skipped in chunk {}.'.format(n))\n",
      "UserWarning: Some frames may be skipped in chunk 10.\n",
      "Process 1020.0-1080.0 seconds:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../python/util.py\", line 1234, in _process_chunk\n",
      "    raise UserWarning('Some frames may be skipped in chunk {}.'.format(n))\n",
      "UserWarning: Some frames may be skipped in chunk 17.\n",
      "Process 1080.0-1140.0 seconds:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../python/util.py\", line 1234, in _process_chunk\n",
      "    raise UserWarning('Some frames may be skipped in chunk {}.'.format(n))\n",
      "UserWarning: Some frames may be skipped in chunk 18.\n",
      "Process 1140.0-1200.0 seconds:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../python/util.py\", line 1234, in _process_chunk\n",
      "    raise UserWarning('Some frames may be skipped in chunk {}.'.format(n))\n",
      "UserWarning: Some frames may be skipped in chunk 19.\n",
      "Process 1740.0-1800.0 seconds:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../python/util.py\", line 1218, in _process_chunk\n",
      "    fig = self._annotate_frame(n_frame, frame)\n",
      "  File \"../python/util.py\", line 1259, in _annotate_frame\n",
      "    ax.imshow(frame)\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/site-packages/matplotlib/__init__.py\", line 1810, in inner\n",
      "    return func(ax, *args, **kwargs)\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/site-packages/matplotlib/axes/_axes.py\", line 5494, in imshow\n",
      "    im.set_data(X)\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/site-packages/matplotlib/image.py\", line 634, in set_data\n",
      "    raise TypeError(\"Image data cannot be converted to float\")\n",
      "TypeError: Image data cannot be converted to float\n",
      "Process 1620.0-1680.0 seconds:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../python/util.py\", line 1234, in _process_chunk\n",
      "    raise UserWarning('Some frames may be skipped in chunk {}.'.format(n))\n",
      "UserWarning: Some frames may be skipped in chunk 27.\n",
      "Process 1560.0-1620.0 seconds:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/james/anaconda3/envs/dlc-ubuntu-GPU/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../python/util.py\", line 1234, in _process_chunk\n",
      "    raise UserWarning('Some frames may be skipped in chunk {}.'.format(n))\n",
      "UserWarning: Some frames may be skipped in chunk 26.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 3978.09 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Annotate settings\n",
    "num_workers = 6\n",
    "chunk_size = 60.0\n",
    "frame_limit = 200\n",
    "\n",
    "# Annotate each video\n",
    "for video_file, pos_file in zip(video_filenames, pos_filenames):\n",
    "    # Load csv data\n",
    "    print('Loading position data in {}...'.format(pos_file))\n",
    "    with open(pos_file, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        print('Column headers:')\n",
    "        for i in range(3):\n",
    "            text = next(reader, None)\n",
    "            print(' '.join(text))\n",
    "    pos = np.loadtxt(pos_file, skiprows=3, delimiter=',')\n",
    "    print('Shape:', pos.shape)  \n",
    "    \n",
    "    # Smooth position data\n",
    "    pos = preprocess_position(pos)\n",
    "    \n",
    "    # Annotate video\n",
    "    print('Starting to annotate video in {}...'.format(video_file))\n",
    "    vid = util.VideoAnnotator(video_file,\n",
    "                              annotate_fn=annotate,\n",
    "                              annotate_kwargs={'pos': pos, 'thresh': 0.9},\n",
    "                              chunk_size=chunk_size,\n",
    "                              output_filename=None,\n",
    "                              output_resolution=[640, 360],\n",
    "                              frame_limit=frame_limit)\n",
    "    t = time.time()\n",
    "    vid.run(max_workers=num_workers, verbose=False)\n",
    "    print('Finished in {:.2f} seconds.\\n'.format(time.time() - t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video compression\n",
    "The webcam videos may be recorded in 'MJPEG' format, which preserves quality at the expense of very large file sizes. We need to pull down videos from Google Drive, compress them locally, and re-upload the compressed version to the same Google Drive folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "mountainlab_pytools module not installed. Some functions from the ephys package may not be available.\n"
     ]
    }
   ],
   "source": [
    "# Numerical tools\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Plotting tools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# OS tools\n",
    "import os\n",
    "from tempfile import TemporaryFile\n",
    "import time\n",
    "import subprocess as sp\n",
    "import getpass\n",
    "\n",
    "# Video tools\n",
    "import moviepy\n",
    "import moviepy.editor\n",
    "\n",
    "# Custom modules\n",
    "import sys\n",
    "sys.path.insert(0, '../python/')\n",
    "import util\n",
    "import session\n",
    "import plot\n",
    "import analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'util' from '../python/util.py'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = util.GoogleDriveService()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_id = service.get_file_ids(filename='Projects',\n",
    "                                 mime_type='application/vnd.google-apps.folder',\n",
    "                                 exact_match=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have to do this the hard way...\n",
    "# https://stackoverflow.com/a/62655764\n",
    "filepath = '/Projects/foraging/data/freely_moving/'\n",
    "folders = [f for f in filepath.split('/') if len(f) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_ids = service.get_file_ids(mime_type='application/vnd.google-apps.folder',\n",
    "                                  pageSize=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_dir = '/media/james/data/foraging/linear_track/raw/19-10-03/' # where to download\n",
    "base_filename = 'R002_d50_2019-10-03-1323'\n",
    "cam_filename = base_filename + '_cam-1.mkv' # if comparing to behavior session\n",
    "#cam_filename = base_filename + '.mkv' # if comparing videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow read/write permissions from directory\n",
    "password = getpass.getpass()\n",
    "command = 'sudo -S chmod 777 %s' % media_dir # -S enables input from stdin\n",
    "os.system('echo %s | %s' % (password, command));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download video file\n",
    "with open(media_dir + cam_filename, 'wb') as f:\n",
    "    service.download(filename=cam_filename,\n",
    "                     chunk_size=1024*1024*100,\n",
    "                     file_object=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to mp4 format if not already\n",
    "if not cam_filename.lower().endswith('.mp4'):\n",
    "    new_filename = '.'.join(cam_filename.split('.')[:-1]) + '.mp4'\n",
    "    cmd = ['ffmpeg',\n",
    "           '-i', media_dir + cam_filename,\n",
    "           '-codec', 'copy',\n",
    "           '-copyts',\n",
    "           '-vsync', 'vfr',\n",
    "           media_dir + new_filename]\n",
    "    cam_filename = new_filename\n",
    "    with sp.Popen(cmd) as p:\n",
    "        p.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get frame rate using ffprobe\n",
    "cmd = ['ffprobe',\n",
    "       '-i', media_dir + cam_filename,\n",
    "       '-select_streams', 'v',\n",
    "       '-show_streams',\n",
    "       '-show_entries', 'stream=avg_frame_rate',\n",
    "       '-of', 'csv=p=0']\n",
    "with sp.Popen(cmd, bufsize=100, stdout=sp.PIPE, stderr=sp.PIPE) as p:\n",
    "    p.wait() # waits until process has terminated\n",
    "    s = p.stdout.read(100)\n",
    "    fps = s.decode().split(',')[0].strip(' \\n')\n",
    "    fps = round(float(fps.split('/')[0]) / float(fps.split('/')[1]))\n",
    "    \n",
    "print(fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get start time using ffprobe\n",
    "cmd = ['ffprobe',\n",
    "       '-i', media_dir + cam_filename,\n",
    "       '-select_streams', 'v',\n",
    "       '-show_entries', 'stream=start_time',\n",
    "       '-of', 'csv=p=0']\n",
    "with sp.Popen(cmd, bufsize=100, stdout=sp.PIPE, stderr=sp.PIPE) as p:\n",
    "    p.wait() # waits until process has terminated\n",
    "    s = p.stdout.read(100)\n",
    "    t_start = float(s.decode().strip(' \\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract timestamps\n",
    "# https://superuser.com/questions/841872/how-do-i-extract-the-timestamps-associated-with-frames-ffmpeg-extracts-from-a-vi\n",
    "ts_filename = base_filename + '_ts.csv'\n",
    "cmd = ['ffprobe',\n",
    "       '-i', media_dir + cam_filename,\n",
    "       '-select_streams', 'v',\n",
    "       '-show_frames',\n",
    "       '-show_entries', 'frame=pkt_pts_time',\n",
    "       '-of', 'csv=p=0']\n",
    "with open(media_dir+ts_filename, 'w') as f, \\\n",
    "     sp.Popen(cmd, stdout=f, stderr=sp.PIPE) as p:\n",
    "    p.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load timestamps\n",
    "ts = np.loadtxt(media_dir + ts_filename)\n",
    "assert ts[0] == t_start\n",
    "duration = ts[-1] - ts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeking in mkv files\n",
    "File seeking in `mkv` (for instance, in the `VideoFileClip.get_frame` method) is unreliable for some reason. There could be a couple of explanations for this. The stack trace (top-down) for a seek call using the `-ss` flag is as follows:\n",
    "\n",
    "Note how start time is added to the requested timestamp (value after `-ss`).\n",
    "```c\n",
    "static int open_input_file(OptionsContext *o, const char *filename\n",
    "{\n",
    "    ...\n",
    "    timestamp = (o->start_time == AV_NOPTS_VALUE) ? 0 : o->start_time;\n",
    "    /* add the stream start time */\n",
    "    if (!o->seek_timestamp && ic->start_time != AV_NOPTS_VALUE)\n",
    "        timestamp += ic->start_time;\n",
    "\n",
    "    /* if seeking requested, we execute it */\n",
    "    if (o->start_time != AV_NOPTS_VALUE) {\n",
    "        int64_t seek_timestamp = timestamp;\n",
    "\n",
    "        if (!(ic->iformat->flags & AVFMT_SEEK_TO_PTS)) {\n",
    "            int dts_heuristic = 0;\n",
    "            for (i=0; i<ic->nb_streams; i++) {\n",
    "                const AVCodecParameters *par = ic->streams[i]->codecpar;\n",
    "                if (par->video_delay) {\n",
    "                    dts_heuristic = 1;\n",
    "                    break;\n",
    "                }\n",
    "            }\n",
    "            if (dts_heuristic) {\n",
    "                seek_timestamp -= 3*AV_TIME_BASE / 23;\n",
    "            }\n",
    "        }\n",
    "        ret = avformat_seek_file(ic, -1, INT64_MIN, seek_timestamp, seek_timestamp, 0);\n",
    "        if (ret < 0) {\n",
    "            av_log(NULL, AV_LOG_WARNING, \"%s: could not seek to position %0.3f\\n\",\n",
    "                   filename, (double)timestamp / AV_TIME_BASE);\n",
    "        }\n",
    "    }\n",
    "    ...\n",
    "}\n",
    "``` \n",
    "[link](https://github.com/FFmpeg/FFmpeg/blob/master/fftools/ffmpeg_opt.c#L1160-1187)\n",
    "\n",
    "Because we get the warning \"could not seek to position\", we know that `avformat_seek_file` must at some point return `-1`. This method attempts to call a `read_seek2` if the `AVFormatContext` (in this case `MatroskaDemuxContext`) has it; otherwise, it falls back on the original `read_seek` method.\n",
    "```c\n",
    "int avformat_seek_file(AVFormatContext *s, int stream_index, int64_t min_ts,\n",
    "                       int64_t ts, int64_t max_ts, int flags)\n",
    "{\n",
    "    ...\n",
    "    if (s->iformat->read_seek2) {\n",
    "        ...\n",
    "    }\n",
    "    ...\n",
    "    if (s->iformat->read_timestamp) {\n",
    "        // try to seek via read_timestamp()\n",
    "    }\n",
    "\n",
    "    // Fall back on old API if new is not implemented but old is.\n",
    "    // Note the old API has somewhat different semantics.\n",
    "    if (s->iformat->read_seek || 1) {\n",
    "        int dir = (ts - (uint64_t)min_ts > (uint64_t)max_ts - ts ? AVSEEK_FLAG_BACKWARD : 0);\n",
    "        int ret = av_seek_frame(s, stream_index, ts, flags | dir);\n",
    "        if (ret<0 && ts != min_ts && max_ts != ts) {\n",
    "            ret = av_seek_frame(s, stream_index, dir ? max_ts : min_ts, flags | dir);\n",
    "            if (ret >= 0)\n",
    "                ret = av_seek_frame(s, stream_index, ts, flags | (dir^AVSEEK_FLAG_BACKWARD));\n",
    "        }\n",
    "        return ret;\n",
    "    } \n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "As can be seen from the `MatroskaDemuxContext`, only a `read_seek` method is defined:\n",
    "```c\n",
    "AVInputFormat ff_matroska_demuxer = {\n",
    "    .name           = \"matroska,webm\",\n",
    "    .long_name      = NULL_IF_CONFIG_SMALL(\"Matroska / WebM\"),\n",
    "    .extensions     = \"mkv,mk3d,mka,mks\",\n",
    "    .priv_data_size = sizeof(MatroskaDemuxContext),\n",
    "    .read_probe     = matroska_probe,\n",
    "    .read_header    = matroska_read_header,\n",
    "    .read_packet    = matroska_read_packet,\n",
    "    .read_close     = matroska_read_close,\n",
    "    .read_seek      = matroska_read_seek,\n",
    "    .mime_type      = \"audio/webm,audio/x-matroska,video/webm,video/x-matroska\"\n",
    "};\n",
    "```\n",
    "[link](https://github.com/FFmpeg/FFmpeg/blob/master/libavformat/matroskadec.c#L4050)\n",
    "\n",
    "So `read_seek` called from `avformat_seek_file` goes to (`av_seek_file`, which goes to `seek_frame_internal`, which calls) `matroska_read_seek`:\n",
    "```c\n",
    "static int matroska_read_seek(AVFormatContext *s, int stream_index,\n",
    "                              int64_t timestamp, int flags)\n",
    "{\n",
    "    ...\n",
    "    timestamp = FFMAX(timestamp, st->index_entries[0].timestamp);\n",
    "\n",
    "    if ((index = av_index_search_timestamp(st, timestamp, flags)) < 0 || index == st->nb_index_entries - 1) {\n",
    "        matroska_reset_status(matroska, 0, st->index_entries[st->nb_index_entries - 1].pos);\n",
    "        while ((index = av_index_search_timestamp(st, timestamp, flags)) < 0 || index == st->nb_index_entries - 1) {\n",
    "            matroska_clear_queue(matroska);\n",
    "            if (matroska_parse_cluster(matroska) < 0)\n",
    "                break;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    matroska_clear_queue(matroska);\n",
    "    if (index < 0 || (matroska->cues_parsing_deferred < 0 && index == st->nb_index_entries - 1))\n",
    "        goto err;\n",
    "\n",
    "    tracks = matroska->tracks.elem;\n",
    "    for (i = 0; i < matroska->tracks.nb_elem; i++) {\n",
    "        tracks[i].audio.pkt_cnt        = 0;\n",
    "        tracks[i].audio.sub_packet_cnt = 0;\n",
    "        tracks[i].audio.buf_timecode   = AV_NOPTS_VALUE;\n",
    "        tracks[i].end_timecode         = 0;\n",
    "    }\n",
    "\n",
    "    /* We seek to a level 1 element, so set the appropriate status. */\n",
    "    matroska_reset_status(matroska, 0, st->index_entries[index].pos);\n",
    "    if (flags & AVSEEK_FLAG_ANY) {\n",
    "        st->skip_to_keyframe = 0;\n",
    "        matroska->skip_to_timecode = timestamp;\n",
    "    } else {\n",
    "        st->skip_to_keyframe = 1;\n",
    "        matroska->skip_to_timecode = st->index_entries[index].timestamp;\n",
    "    }\n",
    "    matroska->skip_to_keyframe = 1;\n",
    "    matroska->done             = 0;\n",
    "    ff_update_cur_dts(s, st, st->index_entries[index].timestamp);\n",
    "    return 0;\n",
    "err:\n",
    "    // slightly hackish but allows proper fallback to\n",
    "    // the generic seeking code.\n",
    "    matroska_reset_status(matroska, 0, -1);\n",
    "    matroska->resync_pos = -1;\n",
    "    matroska_clear_queue(matroska);\n",
    "    st->skip_to_keyframe =\n",
    "    matroska->skip_to_keyframe = 0;\n",
    "    matroska->done = 0;\n",
    "    return -1;\n",
    "}\n",
    "```\n",
    "[link](https://github.com/FFmpeg/FFmpeg/blob/master/libavformat/matroskadec.c#L3765-3811)\n",
    "\n",
    "This function has to return `-1` at some point, which means that it must go to `err`. The `index` returned by `av_index_search_timestamp` comes from `ff_index_search_timestamp`, which performs a binary search of the time window:\n",
    "\n",
    "```c\n",
    "int ff_index_search_timestamp(const AVIndexEntry *entries, int nb_entries,\n",
    "                              int64_t wanted_timestamp, int flags)\n",
    "{\n",
    "    int a, b, m;\n",
    "    int64_t timestamp;\n",
    "\n",
    "    a = -1;\n",
    "    b = nb_entries;\n",
    "\n",
    "    // Optimize appending index entries at the end.\n",
    "    if (b && entries[b - 1].timestamp < wanted_timestamp)\n",
    "        a = b - 1;\n",
    "\n",
    "    while (b - a > 1) {\n",
    "        m         = (a + b) >> 1;\n",
    "\n",
    "        // Search for the next non-discarded packet.\n",
    "        while ((entries[m].flags & AVINDEX_DISCARD_FRAME) && m < b && m < nb_entries - 1) {\n",
    "            m++;\n",
    "            if (m == b && entries[m].timestamp >= wanted_timestamp) {\n",
    "                m = b - 1;\n",
    "                break;\n",
    "            }\n",
    "        }\n",
    "\n",
    "        timestamp = entries[m].timestamp;\n",
    "        if (timestamp >= wanted_timestamp)\n",
    "            b = m;\n",
    "        if (timestamp <= wanted_timestamp)\n",
    "            a = m;\n",
    "    }\n",
    "    m = (flags & AVSEEK_FLAG_BACKWARD) ? a : b;\n",
    "\n",
    "    if (!(flags & AVSEEK_FLAG_ANY))\n",
    "        while (m >= 0 && m < nb_entries &&\n",
    "               !(entries[m].flags & AVINDEX_KEYFRAME))\n",
    "            m += (flags & AVSEEK_FLAG_BACKWARD) ? -1 : 1;\n",
    "\n",
    "    if (m == nb_entries)\n",
    "        return -1;\n",
    "    return m;\n",
    "}\n",
    "```\n",
    "[link](https://github.com/FFmpeg/FFmpeg/blob/master/libavformat/utils.c#L2053-2094)\n",
    "\n",
    "\n",
    "This could be resulting in `index = -1` and leading us to `err`. However, we also get the following warning in the `ffmpeg` output:\n",
    "\n",
    "```shell\n",
    "[matroska,webm @ 0x19cd9e0] Invalid EBML number size tag 0x01 at pos 782 (0x30e)\n",
    "```\n",
    "\n",
    "Note the call to `matroska_parse_cluster` in `matroska_read_seek`; particularly, if it returns `-1`, this could also lead to `err`. `matroska_parse_cluster` calls `ebml_parse`([link](https://github.com/FFmpeg/FFmpeg/blob/master/libavformat/matroskadec.c#L1163)), which, depending on the version of `ffmpeg`, can lead to the warning shown above.\n",
    "\n",
    "So in conclusion, the issue with seeking in matroska files is probably due to one of two things: either a problem with reformatting timestamps in the `read_seek` code block instead of `read_seek2`, or a problem parsing EBML numbers for some frames (why, I'm not sure). In any case, remuxing (but *not* transcoding) to `mp4` seems to fix the seeking issues:\n",
    "\n",
    "```shell\n",
    "ffmpeg -i <filename>.mkv -codec copy -copyts -vsync vfr <filename>.mp4\n",
    "```\n",
    "\n",
    "The `-copyts` flag is important; otherwise, `pts` will be re-encoded from zero in the new file. Additionally, setting `-vsync` to `vfr` allows frames to pass through with their timestamps rather than being duplicated or dropped to maintain a constant frame rate (`cfr`). Although this doesn't appear to make a difference on videos re-muxed so far, the `mp4` demuxer defaults to `cfr`, whereas the `mkv` muxer defaults to `vfr`, so it's probably worth specifying `vfr` just to be safe. The internal frame rate (`r_frame_rate`) may increase to better match timestamps, but this won't affect the actual number of frames. (see [here](https://superuser.com/questions/602950/problems-with-frame-rate-on-video-conversion-using-ffmpeg-with-libx264) or [here](https://video.stackexchange.com/questions/20789/ffmpeg-default-output-frame-rate) for more details) The `pts` may change as well, but that is due to a change in `time_base`; `pkt_pts_time` and `pkt_dts_time` should remain the same, since `pkt_pts` = `time_base` * `pkt_pts_time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_audio = np.loadtxt('/media/james/data/foraging/linear_track/raw/19-10-03/pts_audio.txt')\n",
    "pts_video = np.loadtxt('/media/james/data/foraging/linear_track/raw/19-10-03/pts_video.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(pts_audio))[:500]/len(pts_audio), pts_audio[:500])\n",
    "plt.plot(np.arange(len(pts_video))[:500]/len(pts_video), pts_video[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "pts_audio_interp = scipy.interpolate.interp1d(np.arange(len(pts_audio))/len(pts_audio), pts_audio)\n",
    "pts_video_interp = scipy.interpolate.interp1d(np.arange(len(pts_video))/len(pts_video), pts_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = np.linspace(0.0, 0.99, 10000)\n",
    "plt.plot(pts_video_interp(tt) - pts_audio_interp(tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "\n",
    "audio_filename = '/media/james/data/foraging/linear_track/raw/19-10-03/audio.wav'\n",
    "fs, data = wavfile.read(audio_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data/2**15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (behavior)",
   "language": "python",
   "name": "behavior"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
